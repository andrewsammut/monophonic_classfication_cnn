{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "from tensorflow.keras import layers, models, utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A#3', 'A#4', 'A3', 'A4', 'B3', 'B4', 'C#3', 'C#4', 'C3', 'C4', 'D#3', 'D#4', 'D3', 'D4', 'E3', 'E4', 'F#3', 'F#4', 'F3', 'F4', 'G3', 'G4']\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# Create list of all targets (minus background noise)\n",
    "\n",
    "dataset_path = 'C:\\\\Users\\\\Greg\\\\ML\\\\Technical\\\\project\\\\git2\\\\monophonic_classfication_cnn\\\\padded'\n",
    "all_targets = all_targets = [name for name in listdir(dataset_path) if isdir(join(dataset_path, name))]\n",
    "all_targets.remove('_background_noise_')\n",
    "print(all_targets)\n",
    "numclasses = len(all_targets)\n",
    "print(numclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "feature_sets_path = 'C:\\\\Users\\\\Greg\\\\ML\\\\Technical\\\\project\\\\git2\\\\monophonic_classfication_cnn\\\\audioScripts'\n",
    "feature_sets_filename = 'all_targets_mfcc_sets.npz'\n",
    "model_filename = 'AudioModel.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "# Load feature sets\n",
    "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\n",
    "print(feature_sets.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 16, 16)\n",
      "(128, 16, 16)\n",
      "(128, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "# Look at tensor dimensions\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  5.  1.  9. 19. 17.  1.  0. 17. 13.  5.  9.  1.  1.  7.  7.  7.  7.\n",
      " 15. 19.  0.  7.  8.  8. 14.  6. 11.  3. 14.  1. 10. 12. 14.  5. 15.  2.\n",
      "  1.  5. 10.  6. 15. 14. 19. 18.  8.  3. 17. 15. 17. 19.  9.  2. 13. 19.\n",
      " 18. 11.  3.  7.  0. 19. 11. 20. 13.  9. 13.  4. 19. 10. 10. 16. 18. 16.\n",
      " 17. 10. 13. 17. 19.  2.  4. 13.  7.  7. 11.  1. 21. 16. 10. 20.  1.  8.\n",
      " 16. 15. 14. 20.  3. 13. 20.  3.  2. 14.  9. 13.  7.  2. 16.  2.  2. 16.\n",
      "  5. 16.  9. 16.  6. 11. 17.  6. 11. 10. 21. 18. 16. 11.  7. 19. 11.  3.\n",
      " 10.  8.]\n"
     ]
    }
   ],
   "source": [
    "# Peek at labels\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ground truth arrays to one wake word (1) and 'other' (0)\n",
    "#ytr = []\n",
    "#yv = []\n",
    "#yts = []\n",
    "#count = 1\n",
    "#for pitch in all_targets:\n",
    "#    pitch_index = all_targets.index(pitch)\n",
    "#    ytr.append(np.equal(y_train, pitch_index).astype('float64'))\n",
    "#    yv.append( np.equal(y_val, pitch_index).astype('float64'))\n",
    "#    yts.append(np.equal(y_test, pitch_index).astype('float64'))\n",
    "    #count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.  9. 21. ...  1. 15.  7.]\n"
     ]
    }
   ],
   "source": [
    "# Peek at labels after conversion\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentage of 'stop' appear in validation labels\n",
    "#print(sum(y_val) / len(y_val))\n",
    "#print(1 - sum(y_val) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dimensions of our input data\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 16, 16, 1)\n",
      "(128, 16, 16, 1)\n",
      "(128, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN for TF expects (batch, height, width, channels)\n",
    "# So we reshape the input tensors with a \"color\" channel of 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "y_train = utils.to_categorical(y_train, numclasses)\n",
    "y_test = utils.to_categorical(y_test, numclasses)\n",
    "y_val = utils.to_categorical(y_val, numclasses)\n",
    "\n",
    "#fig=plt.figure()\n",
    "#plt.imshow(x_val[11], cmap='inferno', origin='lower')\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Input shape for CNN is size of MFCC of 1 sample\n",
    "sample_shape = x_test.shape[1:]\n",
    "print(sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "# Based on: https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu',input_shape=sample_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(numclasses, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 15, 15, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 7, 7, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 32)          4128      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 2, 64)          8256      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 22)                1430      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,134\n",
      "Trainable params: 18,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training parameters to model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3681 - acc: 0.8623 - val_loss: 7.7468 - val_acc: 0.3203\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3317 - acc: 0.8740 - val_loss: 7.6691 - val_acc: 0.3047\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3636 - acc: 0.8555 - val_loss: 7.3694 - val_acc: 0.3125\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3324 - acc: 0.8760 - val_loss: 7.2238 - val_acc: 0.3125\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3373 - acc: 0.8643 - val_loss: 7.2778 - val_acc: 0.3047\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3294 - acc: 0.8750 - val_loss: 7.3746 - val_acc: 0.2891\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3243 - acc: 0.8662 - val_loss: 7.5692 - val_acc: 0.2578\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3397 - acc: 0.8643 - val_loss: 7.9859 - val_acc: 0.3281\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3248 - acc: 0.8701 - val_loss: 8.1008 - val_acc: 0.3359\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3329 - acc: 0.8672 - val_loss: 7.9178 - val_acc: 0.3281\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3618 - acc: 0.8467 - val_loss: 7.4642 - val_acc: 0.3125\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3355 - acc: 0.8623 - val_loss: 8.0156 - val_acc: 0.2734\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3661 - acc: 0.8516 - val_loss: 7.6098 - val_acc: 0.2812\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3561 - acc: 0.8652 - val_loss: 7.9235 - val_acc: 0.3203\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4073 - acc: 0.8418 - val_loss: 7.5304 - val_acc: 0.3281\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4644 - acc: 0.8232 - val_loss: 7.1641 - val_acc: 0.2891\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3662 - acc: 0.8408 - val_loss: 7.1694 - val_acc: 0.2969\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3851 - acc: 0.8574 - val_loss: 7.9232 - val_acc: 0.3125\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4604 - acc: 0.8115 - val_loss: 6.9571 - val_acc: 0.2891\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4101 - acc: 0.8506 - val_loss: 6.8010 - val_acc: 0.3203\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3894 - acc: 0.8594 - val_loss: 7.2897 - val_acc: 0.3281\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3737 - acc: 0.8438 - val_loss: 6.9644 - val_acc: 0.2656\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3373 - acc: 0.8721 - val_loss: 6.6471 - val_acc: 0.3125\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4148 - acc: 0.8184 - val_loss: 7.0969 - val_acc: 0.2969\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3856 - acc: 0.8613 - val_loss: 7.3552 - val_acc: 0.3359\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3368 - acc: 0.8672 - val_loss: 7.4430 - val_acc: 0.3281\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3539 - acc: 0.8545 - val_loss: 7.4703 - val_acc: 0.3125\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3739 - acc: 0.8428 - val_loss: 7.6754 - val_acc: 0.2969\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3479 - acc: 0.8555 - val_loss: 7.2072 - val_acc: 0.3047\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3410 - acc: 0.8682 - val_loss: 7.3470 - val_acc: 0.2812\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3731 - acc: 0.8652 - val_loss: 7.2015 - val_acc: 0.2891\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3793 - acc: 0.8506 - val_loss: 7.5396 - val_acc: 0.3047\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3697 - acc: 0.8516 - val_loss: 7.3150 - val_acc: 0.3125\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4096 - acc: 0.8467 - val_loss: 6.9974 - val_acc: 0.2578\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4197 - acc: 0.8418 - val_loss: 6.8139 - val_acc: 0.2734\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4159 - acc: 0.8350 - val_loss: 7.3625 - val_acc: 0.2812\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4073 - acc: 0.8428 - val_loss: 7.4134 - val_acc: 0.2969\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4117 - acc: 0.8418 - val_loss: 7.5502 - val_acc: 0.3438\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4246 - acc: 0.8301 - val_loss: 8.0020 - val_acc: 0.2656\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4829 - acc: 0.8125 - val_loss: 7.1484 - val_acc: 0.2734\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4484 - acc: 0.8232 - val_loss: 7.6490 - val_acc: 0.2812\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3935 - acc: 0.8486 - val_loss: 7.1894 - val_acc: 0.2891\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4237 - acc: 0.8252 - val_loss: 7.0210 - val_acc: 0.2969\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3646 - acc: 0.8555 - val_loss: 6.7184 - val_acc: 0.3516\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4114 - acc: 0.8350 - val_loss: 6.8251 - val_acc: 0.3359\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3750 - acc: 0.8477 - val_loss: 7.8229 - val_acc: 0.2969\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3599 - acc: 0.8555 - val_loss: 7.5625 - val_acc: 0.3203\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3804 - acc: 0.8389 - val_loss: 7.8492 - val_acc: 0.3203\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3156 - acc: 0.8730 - val_loss: 7.6044 - val_acc: 0.3203\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3429 - acc: 0.8584 - val_loss: 7.7554 - val_acc: 0.3047\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3284 - acc: 0.8770 - val_loss: 7.7973 - val_acc: 0.2969\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3337 - acc: 0.8633 - val_loss: 7.6942 - val_acc: 0.3203\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3434 - acc: 0.8633 - val_loss: 7.5977 - val_acc: 0.2969\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3277 - acc: 0.8750 - val_loss: 7.7850 - val_acc: 0.3125\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3414 - acc: 0.8574 - val_loss: 7.7277 - val_acc: 0.2891\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3303 - acc: 0.8662 - val_loss: 7.4872 - val_acc: 0.3125\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3664 - acc: 0.8594 - val_loss: 7.5557 - val_acc: 0.3516\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3789 - acc: 0.8584 - val_loss: 7.3037 - val_acc: 0.3203\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3848 - acc: 0.8486 - val_loss: 7.0990 - val_acc: 0.2969\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3518 - acc: 0.8555 - val_loss: 7.5482 - val_acc: 0.2812\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4002 - acc: 0.8379 - val_loss: 7.8588 - val_acc: 0.2812\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3654 - acc: 0.8535 - val_loss: 7.5793 - val_acc: 0.2656\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3642 - acc: 0.8428 - val_loss: 7.8980 - val_acc: 0.3125\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3656 - acc: 0.8506 - val_loss: 7.5494 - val_acc: 0.2891\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.3689 - acc: 0.8535 - val_loss: 7.2435 - val_acc: 0.2812\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3823 - acc: 0.8574 - val_loss: 7.2164 - val_acc: 0.2969\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3563 - acc: 0.8516 - val_loss: 7.9188 - val_acc: 0.2734\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3628 - acc: 0.8496 - val_loss: 7.6308 - val_acc: 0.3359\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3236 - acc: 0.8730 - val_loss: 7.6876 - val_acc: 0.2969\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3401 - acc: 0.8613 - val_loss: 7.5569 - val_acc: 0.3125\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3515 - acc: 0.8662 - val_loss: 7.4985 - val_acc: 0.2656\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3766 - acc: 0.8438 - val_loss: 8.0235 - val_acc: 0.3438\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3546 - acc: 0.8604 - val_loss: 7.7345 - val_acc: 0.3125\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3623 - acc: 0.8516 - val_loss: 7.7326 - val_acc: 0.3203\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3289 - acc: 0.8662 - val_loss: 7.4707 - val_acc: 0.3359\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3329 - acc: 0.8721 - val_loss: 7.4872 - val_acc: 0.3438\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3759 - acc: 0.8467 - val_loss: 7.0562 - val_acc: 0.3281\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3445 - acc: 0.8652 - val_loss: 7.9102 - val_acc: 0.2969\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3349 - acc: 0.8633 - val_loss: 7.7626 - val_acc: 0.3281\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3216 - acc: 0.8779 - val_loss: 7.7386 - val_acc: 0.3203\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3626 - acc: 0.8672 - val_loss: 7.6712 - val_acc: 0.3750\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3693 - acc: 0.8594 - val_loss: 6.6915 - val_acc: 0.3750\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3595 - acc: 0.8525 - val_loss: 7.4129 - val_acc: 0.3203\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4075 - acc: 0.8311 - val_loss: 7.1512 - val_acc: 0.2969\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3918 - acc: 0.8379 - val_loss: 7.3463 - val_acc: 0.2891\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3288 - acc: 0.8564 - val_loss: 7.7285 - val_acc: 0.2422\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3403 - acc: 0.8516 - val_loss: 7.7269 - val_acc: 0.3047\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3630 - acc: 0.8555 - val_loss: 8.1755 - val_acc: 0.3203\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3647 - acc: 0.8477 - val_loss: 7.9410 - val_acc: 0.3438\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3778 - acc: 0.8398 - val_loss: 7.9531 - val_acc: 0.2734\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4304 - acc: 0.8350 - val_loss: 7.2329 - val_acc: 0.3203\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3950 - acc: 0.8467 - val_loss: 7.6409 - val_acc: 0.2812\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3990 - acc: 0.8320 - val_loss: 7.4001 - val_acc: 0.3203\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3679 - acc: 0.8535 - val_loss: 7.5908 - val_acc: 0.2969\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4358 - acc: 0.8418 - val_loss: 7.0373 - val_acc: 0.3125\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4286 - acc: 0.8320 - val_loss: 7.6979 - val_acc: 0.3125\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3603 - acc: 0.8535 - val_loss: 7.0562 - val_acc: 0.2812\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3736 - acc: 0.8516 - val_loss: 7.5650 - val_acc: 0.2578\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4001 - acc: 0.8359 - val_loss: 7.2382 - val_acc: 0.3047\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3567 - acc: 0.8564 - val_loss: 7.6610 - val_acc: 0.2734\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3692 - acc: 0.8643 - val_loss: 6.8951 - val_acc: 0.3047\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3549 - acc: 0.8535 - val_loss: 7.4420 - val_acc: 0.3125\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3814 - acc: 0.8477 - val_loss: 7.2331 - val_acc: 0.3359\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4437 - acc: 0.8262 - val_loss: 7.7043 - val_acc: 0.2578\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3485 - acc: 0.8604 - val_loss: 8.0135 - val_acc: 0.2734\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3570 - acc: 0.8486 - val_loss: 7.6001 - val_acc: 0.3281\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3250 - acc: 0.8691 - val_loss: 7.8762 - val_acc: 0.2891\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2995 - acc: 0.8828 - val_loss: 8.2173 - val_acc: 0.2812\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3623 - acc: 0.8535 - val_loss: 7.4686 - val_acc: 0.2891\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3007 - acc: 0.8848 - val_loss: 7.9712 - val_acc: 0.3047\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2790 - acc: 0.8838 - val_loss: 8.6677 - val_acc: 0.3203\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3383 - acc: 0.8643 - val_loss: 8.4433 - val_acc: 0.2969\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3445 - acc: 0.8574 - val_loss: 8.0698 - val_acc: 0.2891\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.4038 - acc: 0.8389 - val_loss: 7.7371 - val_acc: 0.2891\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4149 - acc: 0.8369 - val_loss: 7.1519 - val_acc: 0.2812\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4124 - acc: 0.8369 - val_loss: 7.3976 - val_acc: 0.2656\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.4261 - acc: 0.8506 - val_loss: 7.4435 - val_acc: 0.2891\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3984 - acc: 0.8389 - val_loss: 7.9729 - val_acc: 0.3047\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3708 - acc: 0.8477 - val_loss: 7.6972 - val_acc: 0.2969\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3659 - acc: 0.8506 - val_loss: 7.3348 - val_acc: 0.3203\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3549 - acc: 0.8848 - val_loss: 8.1631 - val_acc: 0.2969\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3239 - acc: 0.8828 - val_loss: 8.3860 - val_acc: 0.2969\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3447 - acc: 0.8623 - val_loss: 7.9932 - val_acc: 0.3203\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3290 - acc: 0.8564 - val_loss: 7.8611 - val_acc: 0.2891\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3612 - acc: 0.8584 - val_loss: 7.6465 - val_acc: 0.2891\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3276 - acc: 0.8711 - val_loss: 7.4770 - val_acc: 0.3125\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3742 - acc: 0.8496 - val_loss: 7.5352 - val_acc: 0.2969\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3150 - acc: 0.8730 - val_loss: 8.0733 - val_acc: 0.2969\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3465 - acc: 0.8613 - val_loss: 7.6909 - val_acc: 0.3203\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3516 - acc: 0.8643 - val_loss: 7.6509 - val_acc: 0.3203\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3293 - acc: 0.8623 - val_loss: 8.1477 - val_acc: 0.2969\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3236 - acc: 0.8701 - val_loss: 7.7167 - val_acc: 0.2812\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.2936 - acc: 0.8867 - val_loss: 7.4785 - val_acc: 0.2969\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3179 - acc: 0.8760 - val_loss: 8.0957 - val_acc: 0.3047\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3482 - acc: 0.8643 - val_loss: 7.6062 - val_acc: 0.2969\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3417 - acc: 0.8701 - val_loss: 8.1057 - val_acc: 0.2891\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2992 - acc: 0.8770 - val_loss: 7.7087 - val_acc: 0.3125\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3185 - acc: 0.8662 - val_loss: 8.3109 - val_acc: 0.2812\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3023 - acc: 0.8877 - val_loss: 8.0178 - val_acc: 0.3203\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3298 - acc: 0.8652 - val_loss: 7.6238 - val_acc: 0.3203\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3523 - acc: 0.8564 - val_loss: 8.0844 - val_acc: 0.2812\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3504 - acc: 0.8496 - val_loss: 7.7113 - val_acc: 0.2891\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3100 - acc: 0.8828 - val_loss: 7.9204 - val_acc: 0.2656\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3161 - acc: 0.8779 - val_loss: 8.3246 - val_acc: 0.2969\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3180 - acc: 0.8662 - val_loss: 8.1843 - val_acc: 0.3047\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3081 - acc: 0.8623 - val_loss: 8.1927 - val_acc: 0.3125\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3528 - acc: 0.8535 - val_loss: 7.8659 - val_acc: 0.3281\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3452 - acc: 0.8652 - val_loss: 7.6686 - val_acc: 0.3516\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3328 - acc: 0.8721 - val_loss: 8.0375 - val_acc: 0.3047\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3221 - acc: 0.8662 - val_loss: 7.8930 - val_acc: 0.2812\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3351 - acc: 0.8672 - val_loss: 7.9204 - val_acc: 0.3203\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3395 - acc: 0.8721 - val_loss: 7.7723 - val_acc: 0.3203\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3071 - acc: 0.8740 - val_loss: 8.2426 - val_acc: 0.3203\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3014 - acc: 0.8770 - val_loss: 7.8665 - val_acc: 0.3203\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3158 - acc: 0.8730 - val_loss: 7.7138 - val_acc: 0.2969\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3215 - acc: 0.8691 - val_loss: 7.6840 - val_acc: 0.3203\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3118 - acc: 0.8789 - val_loss: 7.8984 - val_acc: 0.2969\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3069 - acc: 0.8818 - val_loss: 7.7261 - val_acc: 0.3047\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3275 - acc: 0.8789 - val_loss: 8.3098 - val_acc: 0.2891\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3348 - acc: 0.8594 - val_loss: 8.0361 - val_acc: 0.3281\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3044 - acc: 0.8750 - val_loss: 8.4583 - val_acc: 0.3125\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3047 - acc: 0.8682 - val_loss: 8.4997 - val_acc: 0.2891\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.3119 - acc: 0.8799 - val_loss: 8.0945 - val_acc: 0.2578\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3128 - acc: 0.8818 - val_loss: 7.7181 - val_acc: 0.2812\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2993 - acc: 0.8779 - val_loss: 8.2988 - val_acc: 0.2656\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3358 - acc: 0.8691 - val_loss: 7.7967 - val_acc: 0.2656\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3304 - acc: 0.8701 - val_loss: 7.5550 - val_acc: 0.2812\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3682 - acc: 0.8506 - val_loss: 7.7188 - val_acc: 0.2969\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4082 - acc: 0.8389 - val_loss: 7.6063 - val_acc: 0.2969\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3577 - acc: 0.8662 - val_loss: 7.3179 - val_acc: 0.2969\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3811 - acc: 0.8418 - val_loss: 7.7435 - val_acc: 0.2891\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3682 - acc: 0.8584 - val_loss: 7.5746 - val_acc: 0.3125\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3873 - acc: 0.8535 - val_loss: 7.7627 - val_acc: 0.3125\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3414 - acc: 0.8535 - val_loss: 7.2978 - val_acc: 0.2891\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3474 - acc: 0.8525 - val_loss: 8.3486 - val_acc: 0.3047\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3258 - acc: 0.8652 - val_loss: 8.0901 - val_acc: 0.3281\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3747 - acc: 0.8486 - val_loss: 8.3498 - val_acc: 0.2969\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3200 - acc: 0.8789 - val_loss: 7.6836 - val_acc: 0.3125\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3193 - acc: 0.8799 - val_loss: 7.8544 - val_acc: 0.2969\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3720 - acc: 0.8486 - val_loss: 7.8032 - val_acc: 0.3359\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.4159 - acc: 0.8408 - val_loss: 7.3386 - val_acc: 0.2656\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.4398 - acc: 0.8359 - val_loss: 7.2871 - val_acc: 0.2891\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3791 - acc: 0.8525 - val_loss: 7.6443 - val_acc: 0.3359\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3896 - acc: 0.8486 - val_loss: 7.7756 - val_acc: 0.2812\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2748 - acc: 0.9023 - val_loss: 8.3351 - val_acc: 0.2734\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3191 - acc: 0.8730 - val_loss: 7.9192 - val_acc: 0.2969\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3019 - acc: 0.8799 - val_loss: 8.3287 - val_acc: 0.2734\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3471 - acc: 0.8555 - val_loss: 7.6693 - val_acc: 0.2969\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3735 - acc: 0.8457 - val_loss: 7.9791 - val_acc: 0.2734\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3194 - acc: 0.8799 - val_loss: 7.9213 - val_acc: 0.3125\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3321 - acc: 0.8750 - val_loss: 8.7257 - val_acc: 0.3125\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3814 - acc: 0.8506 - val_loss: 7.6671 - val_acc: 0.3516\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3893 - acc: 0.8389 - val_loss: 8.0040 - val_acc: 0.3438\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3711 - acc: 0.8525 - val_loss: 7.7088 - val_acc: 0.3047\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3868 - acc: 0.8438 - val_loss: 7.5966 - val_acc: 0.3203\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3527 - acc: 0.8643 - val_loss: 7.9879 - val_acc: 0.2969\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3648 - acc: 0.8545 - val_loss: 7.6623 - val_acc: 0.3125\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3527 - acc: 0.8643 - val_loss: 7.4653 - val_acc: 0.3125\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3482 - acc: 0.8584 - val_loss: 7.6520 - val_acc: 0.3359\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3595 - acc: 0.8691 - val_loss: 7.6221 - val_acc: 0.2891\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3817 - acc: 0.8594 - val_loss: 7.7484 - val_acc: 0.3359\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3975 - acc: 0.8447 - val_loss: 7.5558 - val_acc: 0.3125\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3537 - acc: 0.8604 - val_loss: 7.9017 - val_acc: 0.2812\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3221 - acc: 0.8809 - val_loss: 8.0888 - val_acc: 0.2891\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3678 - acc: 0.8496 - val_loss: 8.4127 - val_acc: 0.2656\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3213 - acc: 0.8760 - val_loss: 7.4799 - val_acc: 0.2734\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3451 - acc: 0.8701 - val_loss: 8.1473 - val_acc: 0.3047\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3029 - acc: 0.8896 - val_loss: 8.0762 - val_acc: 0.3438\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3700 - acc: 0.8486 - val_loss: 8.3441 - val_acc: 0.3359\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3493 - acc: 0.8623 - val_loss: 8.2913 - val_acc: 0.2656\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3321 - acc: 0.8623 - val_loss: 7.6711 - val_acc: 0.2812\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3320 - acc: 0.8662 - val_loss: 8.3549 - val_acc: 0.2500\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3302 - acc: 0.8760 - val_loss: 8.2928 - val_acc: 0.2969\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3250 - acc: 0.8662 - val_loss: 8.7911 - val_acc: 0.2656\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.2914 - acc: 0.8887 - val_loss: 8.0372 - val_acc: 0.2891\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3042 - acc: 0.8770 - val_loss: 8.3233 - val_acc: 0.2734\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3219 - acc: 0.8682 - val_loss: 8.5347 - val_acc: 0.2812\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3295 - acc: 0.8652 - val_loss: 8.3354 - val_acc: 0.3047\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2953 - acc: 0.8799 - val_loss: 8.7017 - val_acc: 0.2891\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2921 - acc: 0.8799 - val_loss: 8.5176 - val_acc: 0.3047\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3075 - acc: 0.8838 - val_loss: 8.1965 - val_acc: 0.2891\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3497 - acc: 0.8662 - val_loss: 8.3683 - val_acc: 0.3359\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2901 - acc: 0.8857 - val_loss: 8.7055 - val_acc: 0.2969\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2882 - acc: 0.8848 - val_loss: 8.1332 - val_acc: 0.3203\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3544 - acc: 0.8584 - val_loss: 8.3819 - val_acc: 0.2969\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3370 - acc: 0.8652 - val_loss: 8.6341 - val_acc: 0.2578\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3172 - acc: 0.8730 - val_loss: 8.5998 - val_acc: 0.2891\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3094 - acc: 0.8789 - val_loss: 8.0184 - val_acc: 0.3281\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2885 - acc: 0.8984 - val_loss: 8.3027 - val_acc: 0.3281\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2761 - acc: 0.8906 - val_loss: 8.5204 - val_acc: 0.3438\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2911 - acc: 0.8936 - val_loss: 8.3290 - val_acc: 0.3359\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3386 - acc: 0.8652 - val_loss: 7.9642 - val_acc: 0.3438\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3444 - acc: 0.8535 - val_loss: 8.3690 - val_acc: 0.2891\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3289 - acc: 0.8701 - val_loss: 7.9784 - val_acc: 0.3203\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3173 - acc: 0.8809 - val_loss: 7.8976 - val_acc: 0.3438\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3524 - acc: 0.8535 - val_loss: 8.2913 - val_acc: 0.3516\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3448 - acc: 0.8545 - val_loss: 8.5451 - val_acc: 0.2969\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3372 - acc: 0.8604 - val_loss: 8.0653 - val_acc: 0.3438\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3364 - acc: 0.8701 - val_loss: 8.5654 - val_acc: 0.3047\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.3158 - acc: 0.8730 - val_loss: 8.5629 - val_acc: 0.3203\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3212 - acc: 0.8896 - val_loss: 8.1720 - val_acc: 0.3125\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3229 - acc: 0.8682 - val_loss: 8.4015 - val_acc: 0.3281\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3190 - acc: 0.8750 - val_loss: 8.2898 - val_acc: 0.3281\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3547 - acc: 0.8574 - val_loss: 8.2548 - val_acc: 0.2734\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3492 - acc: 0.8643 - val_loss: 7.7114 - val_acc: 0.3203\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3714 - acc: 0.8477 - val_loss: 8.2402 - val_acc: 0.3125\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3661 - acc: 0.8613 - val_loss: 8.4546 - val_acc: 0.3047\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3554 - acc: 0.8477 - val_loss: 8.0449 - val_acc: 0.3281\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.3652 - acc: 0.8535 - val_loss: 7.9252 - val_acc: 0.3359\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3473 - acc: 0.8545 - val_loss: 8.0911 - val_acc: 0.2891\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2845 - acc: 0.8857 - val_loss: 7.9087 - val_acc: 0.3281\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2974 - acc: 0.8838 - val_loss: 8.7425 - val_acc: 0.2891\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3223 - acc: 0.8672 - val_loss: 8.3228 - val_acc: 0.3047\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3583 - acc: 0.8672 - val_loss: 8.3398 - val_acc: 0.2891\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3429 - acc: 0.8613 - val_loss: 8.0288 - val_acc: 0.3047\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3653 - acc: 0.8545 - val_loss: 8.1661 - val_acc: 0.2969\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3347 - acc: 0.8760 - val_loss: 8.4788 - val_acc: 0.2969\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3353 - acc: 0.8701 - val_loss: 8.0193 - val_acc: 0.3203\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3148 - acc: 0.8799 - val_loss: 7.9973 - val_acc: 0.3047\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3050 - acc: 0.8789 - val_loss: 7.9264 - val_acc: 0.2891\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3165 - acc: 0.8643 - val_loss: 8.4392 - val_acc: 0.2891\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3022 - acc: 0.8740 - val_loss: 8.6903 - val_acc: 0.2891\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3701 - acc: 0.8447 - val_loss: 7.7842 - val_acc: 0.3125\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3354 - acc: 0.8643 - val_loss: 8.6587 - val_acc: 0.2500\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3061 - acc: 0.8926 - val_loss: 8.1001 - val_acc: 0.2969\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3373 - acc: 0.8633 - val_loss: 8.1786 - val_acc: 0.3438\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3143 - acc: 0.8818 - val_loss: 8.1449 - val_acc: 0.2969\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2815 - acc: 0.8896 - val_loss: 8.0756 - val_acc: 0.3281\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3112 - acc: 0.8789 - val_loss: 8.5934 - val_acc: 0.2812\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3110 - acc: 0.8828 - val_loss: 8.2427 - val_acc: 0.2969\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.2921 - acc: 0.8799 - val_loss: 8.7159 - val_acc: 0.2734\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3097 - acc: 0.8740 - val_loss: 8.3524 - val_acc: 0.2656\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3308 - acc: 0.8701 - val_loss: 8.0728 - val_acc: 0.3281\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3087 - acc: 0.8740 - val_loss: 8.1613 - val_acc: 0.3359\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3119 - acc: 0.8604 - val_loss: 7.8518 - val_acc: 0.2969\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3080 - acc: 0.8818 - val_loss: 7.9892 - val_acc: 0.2578\n",
      "Epoch 277/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3390 - acc: 0.8711 - val_loss: 8.1495 - val_acc: 0.2891\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3389 - acc: 0.8633 - val_loss: 7.9521 - val_acc: 0.2891\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3342 - acc: 0.8652 - val_loss: 8.4491 - val_acc: 0.3047\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3357 - acc: 0.8691 - val_loss: 8.4960 - val_acc: 0.2812\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3202 - acc: 0.8672 - val_loss: 8.4066 - val_acc: 0.3203\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2868 - acc: 0.8877 - val_loss: 8.3455 - val_acc: 0.2812\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3491 - acc: 0.8623 - val_loss: 8.2466 - val_acc: 0.2578\n",
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3266 - acc: 0.8740 - val_loss: 8.0071 - val_acc: 0.2812\n",
      "Epoch 285/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3112 - acc: 0.8711 - val_loss: 8.3605 - val_acc: 0.2812\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3207 - acc: 0.8721 - val_loss: 8.3687 - val_acc: 0.2969\n",
      "Epoch 287/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3367 - acc: 0.8721 - val_loss: 8.0652 - val_acc: 0.3125\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3653 - acc: 0.8643 - val_loss: 8.5325 - val_acc: 0.2891\n",
      "Epoch 289/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3361 - acc: 0.8613 - val_loss: 8.4730 - val_acc: 0.2812\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3374 - acc: 0.8662 - val_loss: 8.2016 - val_acc: 0.3047\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3585 - acc: 0.8662 - val_loss: 8.3682 - val_acc: 0.2734\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3909 - acc: 0.8506 - val_loss: 8.0209 - val_acc: 0.2891\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3533 - acc: 0.8574 - val_loss: 7.1219 - val_acc: 0.2812\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3437 - acc: 0.8604 - val_loss: 8.3023 - val_acc: 0.3047\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3056 - acc: 0.8740 - val_loss: 8.3469 - val_acc: 0.2656\n",
      "Epoch 296/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3396 - acc: 0.8701 - val_loss: 8.2190 - val_acc: 0.2812\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2607 - acc: 0.8975 - val_loss: 8.2372 - val_acc: 0.2812\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2960 - acc: 0.8789 - val_loss: 8.5794 - val_acc: 0.2891\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2932 - acc: 0.8799 - val_loss: 8.4280 - val_acc: 0.3125\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3224 - acc: 0.8838 - val_loss: 8.5316 - val_acc: 0.2812\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3239 - acc: 0.8896 - val_loss: 8.2599 - val_acc: 0.2812\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3189 - acc: 0.8750 - val_loss: 8.5643 - val_acc: 0.3047\n",
      "Epoch 303/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2866 - acc: 0.8926 - val_loss: 8.3135 - val_acc: 0.2969\n",
      "Epoch 304/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3039 - acc: 0.8770 - val_loss: 7.6395 - val_acc: 0.3438\n",
      "Epoch 305/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3358 - acc: 0.8740 - val_loss: 8.0458 - val_acc: 0.2969\n",
      "Epoch 306/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3247 - acc: 0.8672 - val_loss: 8.4702 - val_acc: 0.2734\n",
      "Epoch 307/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3578 - acc: 0.8613 - val_loss: 7.7305 - val_acc: 0.2969\n",
      "Epoch 308/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3218 - acc: 0.8750 - val_loss: 7.8607 - val_acc: 0.2812\n",
      "Epoch 309/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3337 - acc: 0.8838 - val_loss: 7.7836 - val_acc: 0.3281\n",
      "Epoch 310/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3047 - acc: 0.8789 - val_loss: 8.5695 - val_acc: 0.2891\n",
      "Epoch 311/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3149 - acc: 0.8711 - val_loss: 8.3406 - val_acc: 0.2891\n",
      "Epoch 312/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3132 - acc: 0.8779 - val_loss: 8.4382 - val_acc: 0.2969\n",
      "Epoch 313/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2926 - acc: 0.8789 - val_loss: 8.3613 - val_acc: 0.2969\n",
      "Epoch 314/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2907 - acc: 0.8955 - val_loss: 8.4028 - val_acc: 0.2969\n",
      "Epoch 315/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3159 - acc: 0.8828 - val_loss: 8.3803 - val_acc: 0.2656\n",
      "Epoch 316/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3137 - acc: 0.8867 - val_loss: 8.0298 - val_acc: 0.2734\n",
      "Epoch 317/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3603 - acc: 0.8594 - val_loss: 8.5239 - val_acc: 0.2344\n",
      "Epoch 318/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3093 - acc: 0.8740 - val_loss: 8.3676 - val_acc: 0.2969\n",
      "Epoch 319/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3137 - acc: 0.8799 - val_loss: 8.1014 - val_acc: 0.2969\n",
      "Epoch 320/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3286 - acc: 0.8682 - val_loss: 8.4009 - val_acc: 0.3359\n",
      "Epoch 321/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3212 - acc: 0.8711 - val_loss: 8.7765 - val_acc: 0.3125\n",
      "Epoch 322/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3855 - acc: 0.8418 - val_loss: 8.4486 - val_acc: 0.2578\n",
      "Epoch 323/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3901 - acc: 0.8584 - val_loss: 8.6358 - val_acc: 0.2812\n",
      "Epoch 324/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3409 - acc: 0.8643 - val_loss: 8.1995 - val_acc: 0.2578\n",
      "Epoch 325/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3114 - acc: 0.8848 - val_loss: 8.1328 - val_acc: 0.3281\n",
      "Epoch 326/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3008 - acc: 0.8760 - val_loss: 8.4645 - val_acc: 0.2578\n",
      "Epoch 327/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2997 - acc: 0.8750 - val_loss: 7.8809 - val_acc: 0.2812\n",
      "Epoch 328/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3003 - acc: 0.8916 - val_loss: 8.7688 - val_acc: 0.3047\n",
      "Epoch 329/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3668 - acc: 0.8447 - val_loss: 8.0751 - val_acc: 0.2969\n",
      "Epoch 330/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3509 - acc: 0.8662 - val_loss: 7.5170 - val_acc: 0.2891\n",
      "Epoch 331/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3901 - acc: 0.8408 - val_loss: 8.0053 - val_acc: 0.3281\n",
      "Epoch 332/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3564 - acc: 0.8604 - val_loss: 8.3767 - val_acc: 0.2812\n",
      "Epoch 333/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3753 - acc: 0.8467 - val_loss: 7.5163 - val_acc: 0.3047\n",
      "Epoch 334/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.4069 - acc: 0.8418 - val_loss: 7.9711 - val_acc: 0.2578\n",
      "Epoch 335/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3395 - acc: 0.8594 - val_loss: 8.0158 - val_acc: 0.2891\n",
      "Epoch 336/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3872 - acc: 0.8486 - val_loss: 7.3874 - val_acc: 0.3047\n",
      "Epoch 337/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3439 - acc: 0.8633 - val_loss: 8.9359 - val_acc: 0.2969\n",
      "Epoch 338/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3245 - acc: 0.8789 - val_loss: 8.2321 - val_acc: 0.2734\n",
      "Epoch 339/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3678 - acc: 0.8545 - val_loss: 8.3520 - val_acc: 0.2734\n",
      "Epoch 340/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2977 - acc: 0.8760 - val_loss: 9.0107 - val_acc: 0.3203\n",
      "Epoch 341/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2985 - acc: 0.8857 - val_loss: 9.0892 - val_acc: 0.2812\n",
      "Epoch 342/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3035 - acc: 0.8789 - val_loss: 8.8559 - val_acc: 0.2734\n",
      "Epoch 343/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3037 - acc: 0.8818 - val_loss: 8.2875 - val_acc: 0.3203\n",
      "Epoch 344/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3478 - acc: 0.8525 - val_loss: 8.2314 - val_acc: 0.3047\n",
      "Epoch 345/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.2898 - acc: 0.8857 - val_loss: 8.5754 - val_acc: 0.2891\n",
      "Epoch 346/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3274 - acc: 0.8691 - val_loss: 8.7911 - val_acc: 0.2891\n",
      "Epoch 347/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2877 - acc: 0.8867 - val_loss: 9.0877 - val_acc: 0.2734\n",
      "Epoch 348/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.3066 - acc: 0.8877 - val_loss: 8.2859 - val_acc: 0.2734\n",
      "Epoch 349/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3402 - acc: 0.8721 - val_loss: 8.3838 - val_acc: 0.2969\n",
      "Epoch 350/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3393 - acc: 0.8750 - val_loss: 8.8108 - val_acc: 0.2891\n",
      "Epoch 351/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3585 - acc: 0.8535 - val_loss: 8.4869 - val_acc: 0.2812\n",
      "Epoch 352/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3358 - acc: 0.8701 - val_loss: 8.6598 - val_acc: 0.2812\n",
      "Epoch 353/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3250 - acc: 0.8711 - val_loss: 8.7306 - val_acc: 0.2891\n",
      "Epoch 354/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2804 - acc: 0.8867 - val_loss: 9.8533 - val_acc: 0.2891\n",
      "Epoch 355/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3390 - acc: 0.8682 - val_loss: 8.7798 - val_acc: 0.2891\n",
      "Epoch 356/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3343 - acc: 0.8760 - val_loss: 9.1708 - val_acc: 0.2656\n",
      "Epoch 357/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3179 - acc: 0.8721 - val_loss: 8.6406 - val_acc: 0.2812\n",
      "Epoch 358/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3441 - acc: 0.8613 - val_loss: 8.6226 - val_acc: 0.2812\n",
      "Epoch 359/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3165 - acc: 0.8809 - val_loss: 8.3346 - val_acc: 0.3125\n",
      "Epoch 360/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3279 - acc: 0.8750 - val_loss: 8.2866 - val_acc: 0.3359\n",
      "Epoch 361/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3016 - acc: 0.8750 - val_loss: 9.0551 - val_acc: 0.2656\n",
      "Epoch 362/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3255 - acc: 0.8799 - val_loss: 8.2130 - val_acc: 0.2891\n",
      "Epoch 363/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3639 - acc: 0.8701 - val_loss: 7.8077 - val_acc: 0.3047\n",
      "Epoch 364/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3545 - acc: 0.8535 - val_loss: 8.2923 - val_acc: 0.2734\n",
      "Epoch 365/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3299 - acc: 0.8643 - val_loss: 8.4003 - val_acc: 0.3125\n",
      "Epoch 366/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3230 - acc: 0.8691 - val_loss: 8.5925 - val_acc: 0.2891\n",
      "Epoch 367/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3071 - acc: 0.8721 - val_loss: 8.3908 - val_acc: 0.2969\n",
      "Epoch 368/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2964 - acc: 0.8818 - val_loss: 8.8589 - val_acc: 0.3047\n",
      "Epoch 369/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2806 - acc: 0.8867 - val_loss: 10.0564 - val_acc: 0.2812\n",
      "Epoch 370/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3338 - acc: 0.8711 - val_loss: 8.7737 - val_acc: 0.2734\n",
      "Epoch 371/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3794 - acc: 0.8594 - val_loss: 8.7397 - val_acc: 0.3047\n",
      "Epoch 372/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3369 - acc: 0.8682 - val_loss: 8.9091 - val_acc: 0.3047\n",
      "Epoch 373/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2911 - acc: 0.8809 - val_loss: 8.4897 - val_acc: 0.2812\n",
      "Epoch 374/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2967 - acc: 0.8799 - val_loss: 8.7375 - val_acc: 0.2969\n",
      "Epoch 375/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3076 - acc: 0.8896 - val_loss: 8.2424 - val_acc: 0.2891\n",
      "Epoch 376/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3675 - acc: 0.8564 - val_loss: 8.7188 - val_acc: 0.3281\n",
      "Epoch 377/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3939 - acc: 0.8525 - val_loss: 7.8686 - val_acc: 0.3203\n",
      "Epoch 378/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3788 - acc: 0.8535 - val_loss: 8.5743 - val_acc: 0.2578\n",
      "Epoch 379/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3107 - acc: 0.8750 - val_loss: 8.6364 - val_acc: 0.3125\n",
      "Epoch 380/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3031 - acc: 0.8760 - val_loss: 8.4119 - val_acc: 0.2812\n",
      "Epoch 381/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2689 - acc: 0.8857 - val_loss: 8.5254 - val_acc: 0.3125\n",
      "Epoch 382/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2864 - acc: 0.8877 - val_loss: 8.3520 - val_acc: 0.3125\n",
      "Epoch 383/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2863 - acc: 0.8828 - val_loss: 8.5250 - val_acc: 0.3125\n",
      "Epoch 384/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2634 - acc: 0.8994 - val_loss: 9.6988 - val_acc: 0.2891\n",
      "Epoch 385/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3072 - acc: 0.8760 - val_loss: 8.4519 - val_acc: 0.2891\n",
      "Epoch 386/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2744 - acc: 0.8916 - val_loss: 8.5804 - val_acc: 0.2734\n",
      "Epoch 387/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2969 - acc: 0.8799 - val_loss: 8.7895 - val_acc: 0.2969\n",
      "Epoch 388/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2920 - acc: 0.8916 - val_loss: 8.7701 - val_acc: 0.3125\n",
      "Epoch 389/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2674 - acc: 0.8936 - val_loss: 8.7078 - val_acc: 0.2891\n",
      "Epoch 390/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3448 - acc: 0.8604 - val_loss: 8.6486 - val_acc: 0.3047\n",
      "Epoch 391/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2644 - acc: 0.8975 - val_loss: 9.1072 - val_acc: 0.3047\n",
      "Epoch 392/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3300 - acc: 0.8711 - val_loss: 8.8975 - val_acc: 0.2812\n",
      "Epoch 393/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3111 - acc: 0.8691 - val_loss: 9.0291 - val_acc: 0.2891\n",
      "Epoch 394/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3036 - acc: 0.8809 - val_loss: 8.6826 - val_acc: 0.3125\n",
      "Epoch 395/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3163 - acc: 0.8730 - val_loss: 9.3018 - val_acc: 0.2656\n",
      "Epoch 396/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3206 - acc: 0.8701 - val_loss: 8.4528 - val_acc: 0.3125\n",
      "Epoch 397/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3247 - acc: 0.8691 - val_loss: 8.3805 - val_acc: 0.2891\n",
      "Epoch 398/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2984 - acc: 0.8916 - val_loss: 8.8111 - val_acc: 0.3047\n",
      "Epoch 399/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2754 - acc: 0.8965 - val_loss: 8.8686 - val_acc: 0.2969\n",
      "Epoch 400/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2869 - acc: 0.8857 - val_loss: 9.3366 - val_acc: 0.2656\n",
      "Epoch 401/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2940 - acc: 0.8848 - val_loss: 8.8643 - val_acc: 0.3047\n",
      "Epoch 402/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2916 - acc: 0.8848 - val_loss: 9.2276 - val_acc: 0.2969\n",
      "Epoch 403/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2900 - acc: 0.8828 - val_loss: 8.7759 - val_acc: 0.2812\n",
      "Epoch 404/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2998 - acc: 0.8877 - val_loss: 8.9261 - val_acc: 0.2812\n",
      "Epoch 405/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2661 - acc: 0.8867 - val_loss: 8.9377 - val_acc: 0.2891\n",
      "Epoch 406/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2568 - acc: 0.9023 - val_loss: 9.1903 - val_acc: 0.3125\n",
      "Epoch 407/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2646 - acc: 0.8887 - val_loss: 8.6312 - val_acc: 0.3359\n",
      "Epoch 408/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3191 - acc: 0.8799 - val_loss: 8.6745 - val_acc: 0.2969\n",
      "Epoch 409/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3247 - acc: 0.8770 - val_loss: 8.7278 - val_acc: 0.2734\n",
      "Epoch 410/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2999 - acc: 0.8877 - val_loss: 8.6143 - val_acc: 0.2500\n",
      "Epoch 411/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3028 - acc: 0.8691 - val_loss: 7.8325 - val_acc: 0.3047\n",
      "Epoch 412/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3090 - acc: 0.8848 - val_loss: 9.4831 - val_acc: 0.2812\n",
      "Epoch 413/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3017 - acc: 0.8818 - val_loss: 8.7080 - val_acc: 0.2812\n",
      "Epoch 414/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3212 - acc: 0.8809 - val_loss: 8.9959 - val_acc: 0.2891\n",
      "Epoch 415/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2973 - acc: 0.8916 - val_loss: 8.6691 - val_acc: 0.2891\n",
      "Epoch 416/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3093 - acc: 0.8779 - val_loss: 8.7573 - val_acc: 0.2891\n",
      "Epoch 417/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3391 - acc: 0.8711 - val_loss: 8.3788 - val_acc: 0.2812\n",
      "Epoch 418/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3127 - acc: 0.8740 - val_loss: 8.3737 - val_acc: 0.2812\n",
      "Epoch 419/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3169 - acc: 0.8789 - val_loss: 8.9270 - val_acc: 0.2969\n",
      "Epoch 420/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3004 - acc: 0.8828 - val_loss: 9.3256 - val_acc: 0.3125\n",
      "Epoch 421/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2847 - acc: 0.8838 - val_loss: 8.9550 - val_acc: 0.2734\n",
      "Epoch 422/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2856 - acc: 0.8857 - val_loss: 8.9132 - val_acc: 0.2891\n",
      "Epoch 423/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2876 - acc: 0.8848 - val_loss: 9.1649 - val_acc: 0.2969\n",
      "Epoch 424/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2775 - acc: 0.8906 - val_loss: 8.8070 - val_acc: 0.3047\n",
      "Epoch 425/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3314 - acc: 0.8750 - val_loss: 8.7974 - val_acc: 0.2891\n",
      "Epoch 426/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3392 - acc: 0.8721 - val_loss: 8.6535 - val_acc: 0.3047\n",
      "Epoch 427/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3061 - acc: 0.8750 - val_loss: 8.8165 - val_acc: 0.2734\n",
      "Epoch 428/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2732 - acc: 0.8926 - val_loss: 8.9584 - val_acc: 0.2891\n",
      "Epoch 429/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3223 - acc: 0.8828 - val_loss: 8.9823 - val_acc: 0.2891\n",
      "Epoch 430/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2800 - acc: 0.9023 - val_loss: 8.5381 - val_acc: 0.3047\n",
      "Epoch 431/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3224 - acc: 0.8701 - val_loss: 8.7373 - val_acc: 0.2969\n",
      "Epoch 432/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3067 - acc: 0.8770 - val_loss: 8.5892 - val_acc: 0.3047\n",
      "Epoch 433/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3174 - acc: 0.8691 - val_loss: 8.6676 - val_acc: 0.2656\n",
      "Epoch 434/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.2925 - acc: 0.8818 - val_loss: 9.5939 - val_acc: 0.2656\n",
      "Epoch 435/500\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2726 - acc: 0.8975 - val_loss: 9.2016 - val_acc: 0.3047\n",
      "Epoch 436/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.3137 - acc: 0.8682 - val_loss: 9.3697 - val_acc: 0.2812\n",
      "Epoch 437/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3050 - acc: 0.8691 - val_loss: 9.0176 - val_acc: 0.3125\n",
      "Epoch 438/500\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.3114 - acc: 0.8887 - val_loss: 9.3716 - val_acc: 0.2969\n",
      "Epoch 439/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2938 - acc: 0.8896 - val_loss: 9.2946 - val_acc: 0.2891\n",
      "Epoch 440/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.3183 - acc: 0.8760 - val_loss: 9.1025 - val_acc: 0.2656\n",
      "Epoch 441/500\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.3140 - acc: 0.8672 - val_loss: 8.7468 - val_acc: 0.2734\n",
      "Epoch 442/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.3780 - acc: 0.8584 - val_loss: 9.0601 - val_acc: 0.2578\n",
      "Epoch 443/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3212 - acc: 0.8809 - val_loss: 8.6480 - val_acc: 0.3125\n",
      "Epoch 444/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.2945 - acc: 0.8809 - val_loss: 8.5119 - val_acc: 0.2891\n",
      "Epoch 445/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2965 - acc: 0.8975 - val_loss: 8.6940 - val_acc: 0.2891\n",
      "Epoch 446/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3636 - acc: 0.8594 - val_loss: 9.0235 - val_acc: 0.2656\n",
      "Epoch 447/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3589 - acc: 0.8711 - val_loss: 8.7441 - val_acc: 0.2812\n",
      "Epoch 448/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3240 - acc: 0.8799 - val_loss: 9.2760 - val_acc: 0.2422\n",
      "Epoch 449/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3224 - acc: 0.8828 - val_loss: 8.7152 - val_acc: 0.2812\n",
      "Epoch 450/500\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 0.3140 - acc: 0.8721 - val_loss: 8.9595 - val_acc: 0.2734\n",
      "Epoch 451/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2936 - acc: 0.8682 - val_loss: 9.0060 - val_acc: 0.3281\n",
      "Epoch 452/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2923 - acc: 0.8789 - val_loss: 9.1011 - val_acc: 0.2578\n",
      "Epoch 453/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2549 - acc: 0.9033 - val_loss: 9.1768 - val_acc: 0.2734\n",
      "Epoch 454/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2777 - acc: 0.8926 - val_loss: 9.2320 - val_acc: 0.2734\n",
      "Epoch 455/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2737 - acc: 0.8818 - val_loss: 8.9796 - val_acc: 0.2891\n",
      "Epoch 456/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.2958 - acc: 0.8838 - val_loss: 9.4095 - val_acc: 0.2656\n",
      "Epoch 457/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3007 - acc: 0.8730 - val_loss: 8.9297 - val_acc: 0.2578\n",
      "Epoch 458/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3203 - acc: 0.8750 - val_loss: 9.1824 - val_acc: 0.2500\n",
      "Epoch 459/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3401 - acc: 0.8740 - val_loss: 9.3688 - val_acc: 0.2656\n",
      "Epoch 460/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3710 - acc: 0.8604 - val_loss: 8.4576 - val_acc: 0.2891\n",
      "Epoch 461/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3589 - acc: 0.8613 - val_loss: 7.5631 - val_acc: 0.2969\n",
      "Epoch 462/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3541 - acc: 0.8545 - val_loss: 7.1929 - val_acc: 0.3203\n",
      "Epoch 463/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3820 - acc: 0.8564 - val_loss: 8.1663 - val_acc: 0.3047\n",
      "Epoch 464/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3324 - acc: 0.8574 - val_loss: 8.3655 - val_acc: 0.2500\n",
      "Epoch 465/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3641 - acc: 0.8682 - val_loss: 8.4385 - val_acc: 0.2734\n",
      "Epoch 466/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3647 - acc: 0.8545 - val_loss: 8.2155 - val_acc: 0.3125\n",
      "Epoch 467/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3662 - acc: 0.8672 - val_loss: 8.2694 - val_acc: 0.2812\n",
      "Epoch 468/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3445 - acc: 0.8613 - val_loss: 8.6603 - val_acc: 0.2812\n",
      "Epoch 469/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3370 - acc: 0.8682 - val_loss: 9.4095 - val_acc: 0.2812\n",
      "Epoch 470/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3492 - acc: 0.8682 - val_loss: 8.3129 - val_acc: 0.2891\n",
      "Epoch 471/500\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.3090 - acc: 0.8770 - val_loss: 8.0978 - val_acc: 0.3047\n",
      "Epoch 472/500\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2900 - acc: 0.8887 - val_loss: 8.5625 - val_acc: 0.2812\n",
      "Epoch 473/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3362 - acc: 0.8740 - val_loss: 9.0697 - val_acc: 0.3047\n",
      "Epoch 474/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3248 - acc: 0.8750 - val_loss: 8.6469 - val_acc: 0.2891\n",
      "Epoch 475/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3645 - acc: 0.8564 - val_loss: 8.9186 - val_acc: 0.3359\n",
      "Epoch 476/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3105 - acc: 0.8682 - val_loss: 9.0968 - val_acc: 0.3203\n",
      "Epoch 477/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3184 - acc: 0.8789 - val_loss: 8.9229 - val_acc: 0.3594\n",
      "Epoch 478/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3430 - acc: 0.8623 - val_loss: 8.7989 - val_acc: 0.3281\n",
      "Epoch 479/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.3441 - acc: 0.8701 - val_loss: 8.3857 - val_acc: 0.2812\n",
      "Epoch 480/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3391 - acc: 0.8691 - val_loss: 9.0077 - val_acc: 0.3203\n",
      "Epoch 481/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3550 - acc: 0.8496 - val_loss: 8.9068 - val_acc: 0.2969\n",
      "Epoch 482/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3475 - acc: 0.8691 - val_loss: 8.9399 - val_acc: 0.3203\n",
      "Epoch 483/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3284 - acc: 0.8701 - val_loss: 9.6647 - val_acc: 0.2656\n",
      "Epoch 484/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2834 - acc: 0.8916 - val_loss: 8.5306 - val_acc: 0.2891\n",
      "Epoch 485/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2848 - acc: 0.8896 - val_loss: 8.6416 - val_acc: 0.2891\n",
      "Epoch 486/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2863 - acc: 0.8975 - val_loss: 8.9744 - val_acc: 0.3203\n",
      "Epoch 487/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2841 - acc: 0.8867 - val_loss: 8.8332 - val_acc: 0.3125\n",
      "Epoch 488/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2660 - acc: 0.8955 - val_loss: 9.2310 - val_acc: 0.2891\n",
      "Epoch 489/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.2891 - acc: 0.8936 - val_loss: 8.9743 - val_acc: 0.2969\n",
      "Epoch 490/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3189 - acc: 0.8760 - val_loss: 8.9247 - val_acc: 0.3125\n",
      "Epoch 491/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2857 - acc: 0.8838 - val_loss: 9.7020 - val_acc: 0.2969\n",
      "Epoch 492/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2986 - acc: 0.8799 - val_loss: 9.0791 - val_acc: 0.2656\n",
      "Epoch 493/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.2942 - acc: 0.8848 - val_loss: 9.2635 - val_acc: 0.3047\n",
      "Epoch 494/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3073 - acc: 0.8838 - val_loss: 9.9270 - val_acc: 0.2891\n",
      "Epoch 495/500\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.3193 - acc: 0.8818 - val_loss: 8.8669 - val_acc: 0.3359\n",
      "Epoch 496/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3195 - acc: 0.8662 - val_loss: 9.3789 - val_acc: 0.2969\n",
      "Epoch 497/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.2860 - acc: 0.8887 - val_loss: 9.8721 - val_acc: 0.3047\n",
      "Epoch 498/500\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 0.3032 - acc: 0.8896 - val_loss: 8.8231 - val_acc: 0.2969\n",
      "Epoch 499/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3369 - acc: 0.8682 - val_loss: 9.0208 - val_acc: 0.3047\n",
      "Epoch 500/500\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.3042 - acc: 0.8809 - val_loss: 9.3611 - val_acc: 0.2969\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "#pitch_index = all_targets.index(pitch)\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=500, \n",
    "                    batch_size=100, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a file\n",
    "models.save_model(model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# See which are 'stop'\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_test):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(idx)\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# See which are 'stop'\n",
    "for idx, y in enumerate(y_test):\n",
    "    if y == 1:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n",
      "Answer: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.4599377e-01 6.5802537e-06 2.1392162e-01 4.4309755e-04 1.4215791e-01\n",
      "  7.4373347e-08 4.7114689e-05 8.6477265e-02 4.3328587e-04 1.1555925e-01\n",
      "  6.8693444e-06 1.7420533e-01 3.3629502e-05 9.8195873e-02 1.0535244e-06\n",
      "  2.2403393e-02 6.4767011e-07 1.6331544e-05 2.1647173e-05 3.5909408e-05\n",
      "  1.2909338e-05 2.6410049e-05]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.99363768e-01 8.13450129e-07 1.77398741e-01 6.63793980e-05\n",
      "  1.34641215e-01 1.44748835e-08 1.17202590e-05 9.74207595e-02\n",
      "  3.81633872e-04 1.44428581e-01 4.83868416e-06 1.15626335e-01\n",
      "  1.21410867e-05 1.20789312e-01 9.49258947e-07 9.83119570e-03\n",
      "  2.90852569e-07 1.23397797e-06 8.25931238e-06 3.38180757e-06\n",
      "  5.77809396e-06 2.71933663e-06]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]  Prediction: [[7.28801660e-06 4.36713845e-01 7.61297727e-08 5.89635602e-06\n",
      "  7.86190139e-06 1.10731639e-01 5.88664086e-08 7.52919732e-05\n",
      "  3.41967194e-07 4.87315390e-07 2.10641127e-09 7.82040370e-05\n",
      "  5.91618573e-07 2.66474376e-06 1.09002003e-05 9.23349056e-04\n",
      "  5.62943933e-06 2.41901189e-01 1.37192915e-08 1.21119358e-01\n",
      "  3.17773338e-05 8.83835480e-02]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[2.0140661e-13 2.1947343e-03 1.0663339e-13 1.5691317e-12 2.7733809e-14\n",
      "  9.9773788e-01 1.0401947e-06 1.0175661e-11 1.4759637e-13 6.9062601e-14\n",
      "  6.2886862e-11 1.1300755e-09 1.1749487e-06 2.0039697e-16 8.4724638e-07\n",
      "  1.0746405e-12 2.3783481e-05 3.5884183e-05 1.5240130e-13 1.8983890e-08\n",
      "  3.7055395e-06 7.9552581e-07]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[2.5537205e-01 9.4465036e-10 2.9486010e-02 3.5820381e-07 3.8711240e-03\n",
      "  1.3031288e-09 5.4277966e-06 1.7529291e-01 3.7980710e-05 3.3581749e-02\n",
      "  3.7734018e-05 4.5280781e-01 5.4001197e-05 4.8001181e-02 4.2287206e-06\n",
      "  1.4364473e-03 5.6412006e-08 6.7352374e-07 2.7371587e-07 2.0027372e-07\n",
      "  9.3213421e-06 4.9789759e-07]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[5.7329441e-04 3.6191653e-02 4.5359773e-03 1.0016493e-03 3.9725205e-01\n",
      "  3.5321376e-05 5.9646793e-04 4.1585327e-03 2.6526250e-04 6.5691836e-02\n",
      "  2.8609397e-06 4.1402094e-03 4.2866287e-04 6.6439859e-03 1.0556878e-04\n",
      "  1.5580375e-04 2.1757258e-05 1.6667247e-01 2.4845198e-05 8.9212596e-02\n",
      "  2.1423027e-03 2.2014691e-01]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]  Prediction: [[3.0261886e-06 3.5626644e-01 4.8482384e-06 3.3227290e-05 1.0237366e-05\n",
      "  6.5869797e-04 6.7605761e-08 5.5392360e-05 2.8780551e-08 2.3228938e-06\n",
      "  5.9844113e-10 1.2771653e-05 8.0972762e-07 2.7203690e-05 3.0953694e-07\n",
      "  5.9020170e-04 6.3059235e-07 3.5507113e-01 1.8632935e-09 4.6546511e-02\n",
      "  4.4941194e-06 2.4071158e-01]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]  Prediction: [[0.01233967 0.0202914  0.03252006 0.02206498 0.02695376 0.00393555\n",
      "  0.06757241 0.11277564 0.00527747 0.0173257  0.01973219 0.04558223\n",
      "  0.09416331 0.06681299 0.0632062  0.16240858 0.0429562  0.00832069\n",
      "  0.03975081 0.02196921 0.09234389 0.02169709]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]  Prediction: [[3.84313836e-07 3.37964366e-07 5.03100091e-06 3.34337855e-08\n",
      "  9.35413627e-05 1.65288796e-07 3.11922096e-02 1.64572368e-04\n",
      "  1.78010598e-01 5.89066876e-05 1.21173665e-01 5.07629181e-07\n",
      "  2.02574253e-01 4.06236242e-04 9.25690532e-02 5.04871480e-07\n",
      "  1.18955508e-01 3.88506720e-07 1.53418377e-01 4.66607707e-06\n",
      "  1.01370960e-01 1.33915862e-07]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]  Prediction: [[3.1301179e-06 5.2288729e-01 1.9327788e-06 3.0282646e-04 6.2537706e-06\n",
      "  5.1624025e-04 1.4938367e-09 6.4796746e-05 1.8238689e-08 3.4580203e-06\n",
      "  6.0993627e-11 9.9037807e-06 2.0284343e-08 1.0022855e-05 3.9108659e-07\n",
      "  4.2185443e-03 4.0293244e-08 2.3133372e-01 1.2095706e-09 1.0055347e-01\n",
      "  2.2170939e-06 1.4008571e-01]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.11520485e-05 8.43899883e-09 5.87136383e-05 1.14222987e-08\n",
      "  1.84419550e-05 1.16732268e-08 2.38030665e-02 1.78522908e-03\n",
      "  5.22011556e-02 8.22727670e-05 2.41908729e-01 1.82951244e-05\n",
      "  1.59820214e-01 3.53816518e-04 4.98373955e-02 6.90723073e-06\n",
      "  3.03047020e-02 1.11324052e-08 1.10804457e-02 3.55916910e-07\n",
      "  4.28709030e-01 5.24855537e-09]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Answer: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[3.9881339e-08 1.4823293e-02 8.3718697e-07 9.7644198e-01 2.0561856e-06\n",
      "  1.0052046e-09 4.6981679e-11 1.8426854e-06 1.2890677e-12 5.6445781e-08\n",
      "  1.0402372e-13 1.1719330e-05 2.0867022e-10 4.7462904e-06 3.8623399e-10\n",
      "  2.9282868e-03 1.2906502e-11 5.8428163e-04 6.5228108e-11 5.3383934e-04\n",
      "  6.6996990e-09 4.6669524e-03]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[2.2223812e-01 8.4210606e-06 7.2180919e-02 1.6627136e-04 1.3223732e-01\n",
      "  1.3659778e-07 2.7372364e-06 6.5519638e-02 2.1355804e-04 1.5589853e-01\n",
      "  6.3958043e-07 1.1220821e-01 1.3607075e-06 1.1098716e-01 9.3136356e-07\n",
      "  1.2831019e-01 7.6430456e-07 1.8987606e-06 6.5858185e-06 7.9411948e-06\n",
      "  4.5825705e-06 4.2303468e-06]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.25789502e-13 8.90801940e-03 6.17801522e-15 2.81318827e-12\n",
      "  3.21827187e-14 9.91084874e-01 1.04018270e-11 1.03234039e-10\n",
      "  3.80059364e-15 6.09472943e-15 1.05741425e-14 3.59931217e-11\n",
      "  5.00006037e-10 3.86610359e-15 3.73087700e-10 7.77459087e-12\n",
      "  2.69843259e-09 3.79098219e-06 2.96750105e-16 1.17724802e-07\n",
      "  5.29883648e-09 3.18862385e-06]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]  Prediction: [[4.22350084e-08 2.74524723e-07 8.77175950e-08 5.34722666e-09\n",
      "  1.34306965e-05 2.91284987e-08 1.23170521e-02 1.93533779e-05\n",
      "  3.72361206e-02 4.42787541e-06 3.46438922e-02 2.08423572e-07\n",
      "  1.52785480e-01 2.99289641e-05 2.61907279e-01 7.36995602e-08\n",
      "  1.10554479e-01 1.94321800e-07 3.70065421e-01 2.32987554e-06\n",
      "  2.04197150e-02 1.31700304e-07]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]  Prediction: [[9.41691837e-07 1.54100146e-08 2.70154169e-06 4.10330481e-09\n",
      "  6.62479579e-05 2.35443931e-08 2.85313558e-02 3.83424573e-04\n",
      "  2.34250575e-01 9.22129620e-05 1.45390064e-01 8.31186696e-07\n",
      "  2.02132136e-01 6.35678705e-04 3.90627012e-02 6.95655160e-07\n",
      "  1.00007430e-01 3.03314920e-08 1.46099374e-01 2.78814184e-07\n",
      "  1.03343286e-01 8.24818258e-09]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Answer: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[2.2135461e-07 7.8308296e-01 7.0565255e-07 1.7274186e-01 3.8614112e-06\n",
      "  7.9913607e-06 4.5336224e-09 4.0278988e-05 6.9066156e-11 2.6708699e-08\n",
      "  1.9132796e-11 9.2971757e-05 3.6040639e-08 1.8160183e-05 7.4347000e-08\n",
      "  4.7626146e-03 4.0356882e-09 8.1607942e-03 5.5612803e-10 5.8618630e-04\n",
      "  1.6016816e-07 3.0500885e-02]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.0679870e-07 1.2253058e-07 1.1396098e-06 2.3847608e-08 7.2813543e-07\n",
      "  1.0272602e-07 1.2503932e-01 2.8572013e-05 3.4997970e-02 2.3359560e-06\n",
      "  9.4287433e-02 1.5323257e-06 1.7010428e-01 8.0035998e-06 6.4547636e-02\n",
      "  2.1056062e-06 3.1178984e-01 3.0691848e-07 1.4068334e-01 4.8359088e-06\n",
      "  5.8500148e-02 3.7661913e-08]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[8.16787406e-07 2.38462690e-07 6.52851577e-06 8.11011347e-08\n",
      "  5.87137940e-04 2.11975035e-07 4.54772264e-02 7.24291895e-04\n",
      "  1.03444055e-01 4.79954673e-04 7.39696175e-02 2.07200037e-06\n",
      "  9.79959294e-02 7.99859234e-04 1.46723837e-01 3.15513432e-07\n",
      "  1.04348756e-01 9.87296787e-08 2.83507407e-01 8.60238470e-06\n",
      "  1.41921803e-01 1.14961165e-06]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[7.7943714e-11 1.1677456e-11 7.8050277e-10 9.2534411e-13 1.4406264e-07\n",
      "  2.3687385e-12 2.8371010e-02 3.6761680e-06 5.1585827e-02 1.4136691e-07\n",
      "  3.6296781e-02 4.3874776e-10 1.8876538e-01 1.6033284e-06 1.3407125e-01\n",
      "  8.6422453e-10 2.0187484e-01 3.2001398e-11 3.4054637e-01 5.8840453e-09\n",
      "  1.8482886e-02 3.4292635e-11]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.7249396e-03 2.1371028e-01 2.4744344e-03 9.7219989e-02 6.8495516e-03\n",
      "  6.7836401e-05 1.9222025e-06 6.6768583e-03 4.2778270e-06 4.4158790e-03\n",
      "  5.1967595e-07 3.6380331e-03 3.0696531e-06 1.6699249e-02 4.0451432e-06\n",
      "  3.9495599e-01 1.8860361e-06 2.1781342e-02 1.2438269e-06 3.0270994e-02\n",
      "  4.0281047e-06 1.9949360e-01]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[2.68873714e-06 1.18277945e-01 7.80923187e-07 4.60100600e-05\n",
      "  3.33823948e-07 9.52610373e-03 3.13496057e-05 4.37943418e-05\n",
      "  6.59022498e-06 7.08671664e-08 2.05445976e-05 5.86076872e-04\n",
      "  7.58386013e-05 1.42389661e-06 1.89582049e-03 6.38800149e-04\n",
      "  1.15194498e-03 8.52674723e-01 3.73191301e-06 1.00934738e-02\n",
      "  7.68240832e-04 4.15375642e-03]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.7704144e-01 7.0377462e-07 9.6790738e-02 2.0361356e-05 1.5901700e-01\n",
      "  8.7718153e-09 7.3689880e-06 1.1001474e-01 1.4292331e-04 1.6170922e-01\n",
      "  1.1065828e-06 9.0977818e-02 2.5485031e-06 1.3474500e-01 1.3348451e-07\n",
      "  6.9510996e-02 3.1859429e-07 2.0329428e-06 1.7779239e-06 7.4408704e-06\n",
      "  4.0364939e-06 2.3034479e-06]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]  Prediction: [[3.50064910e-09 3.03113788e-01 1.55879789e-07 5.67703682e-06\n",
      "  9.21764467e-07 6.10621527e-08 7.40498843e-11 2.40563054e-07\n",
      "  2.27733995e-11 2.02738676e-07 1.05094495e-13 1.80499811e-07\n",
      "  5.30808120e-10 1.14689129e-07 9.15001630e-10 8.25797542e-06\n",
      "  6.16361573e-10 2.71059036e-01 3.52549397e-13 9.32479724e-02\n",
      "  1.00414425e-07 3.32563281e-01]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.6183461e-01 3.8356255e-05 7.1328051e-02 4.5411018e-04 2.2583367e-01\n",
      "  8.1853358e-07 8.2650135e-05 1.2247415e-01 1.2301089e-03 1.6664426e-01\n",
      "  1.8254726e-05 1.2169875e-01 1.6281800e-05 9.5753036e-02 6.5172526e-06\n",
      "  3.2270890e-02 1.0471937e-05 4.5909273e-05 4.4197281e-05 7.6382508e-05\n",
      "  1.1078066e-04 2.7676157e-05]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[5.2668321e-07 4.0168211e-02 1.2719458e-07 1.2499591e-07 4.3084307e-07\n",
      "  9.5015156e-01 5.6210033e-06 4.2118445e-06 1.5837593e-07 1.5037335e-07\n",
      "  2.6660107e-08 3.5284331e-06 3.3874203e-05 9.8394885e-08 6.9951780e-06\n",
      "  1.0505850e-06 2.7051748e-05 5.6254631e-03 6.4273045e-09 5.3708861e-04\n",
      "  3.3574517e-05 3.3999651e-03]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]  Prediction: [[1.51960385e-05 2.06010967e-01 2.47042390e-05 1.90743152e-03\n",
      "  2.28064644e-04 1.16105162e-04 4.67593082e-07 3.70843423e-04\n",
      "  3.12344412e-07 6.88114305e-05 3.67706612e-08 2.52004858e-04\n",
      "  6.34416756e-06 4.87424928e-04 9.68276436e-06 2.28137970e-02\n",
      "  3.87508771e-06 1.50450215e-01 2.87108691e-07 9.47059467e-02\n",
      "  1.88172889e-05 5.22508681e-01]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]  Prediction: [[5.5344418e-09 4.9410608e-01 2.4270793e-08 1.7766117e-05 1.1548307e-06\n",
      "  1.0526115e-07 3.7359141e-10 1.7501047e-06 6.7671473e-11 1.3328025e-07\n",
      "  3.4671539e-12 2.1146491e-07 4.2791988e-09 9.5271946e-07 8.9205212e-09\n",
      "  2.8551265e-05 1.3230851e-09 2.6166892e-02 4.4894009e-11 4.7056407e-02\n",
      "  9.4091121e-08 4.3261990e-01]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]  Prediction: [[2.5512290e-10 1.0416716e-01 2.2718738e-09 6.1101448e-09 7.7987238e-08\n",
      "  1.5534296e-08 2.2661489e-12 7.7977971e-09 7.4183476e-13 1.0577984e-08\n",
      "  1.2965142e-15 3.5852541e-09 2.1185836e-10 4.7866506e-09 5.6094279e-11\n",
      "  7.0820079e-07 2.3720495e-10 5.1101577e-01 4.0841123e-14 1.2840779e-01\n",
      "  6.1417977e-09 2.5640848e-01]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]  Prediction: [[1.2589034e-04 3.3082440e-01 6.3107611e-05 9.9133619e-04 3.8187935e-03\n",
      "  8.3532352e-05 1.9522326e-05 1.5615931e-03 4.1504529e-05 5.9410353e-04\n",
      "  2.6138396e-06 1.2357220e-03 8.3444203e-05 1.0270696e-03 1.0396696e-03\n",
      "  1.4778066e-03 2.1942843e-04 2.1103223e-01 2.7699387e-05 9.5031291e-02\n",
      "  7.7584718e-04 3.4992343e-01]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.74715981e-01 1.34561314e-14 1.22271664e-01 3.21109001e-10\n",
      "  7.11669054e-05 7.21342919e-17 1.64533977e-11 3.43770683e-01\n",
      "  4.50011937e-11 1.07179256e-03 1.71421436e-11 3.54122758e-01\n",
      "  2.54780294e-11 3.88010265e-03 3.31586278e-12 9.58115779e-05\n",
      "  8.64887012e-17 2.51444720e-12 1.35840105e-14 1.31566823e-11\n",
      "  4.16376378e-11 1.24017333e-11]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[8.71065184e-02 6.55402182e-05 4.23212536e-02 3.63537250e-03\n",
      "  3.21260765e-02 3.35997555e-07 4.27289069e-06 1.35581642e-01\n",
      "  9.71954250e-06 1.11954045e-02 2.77802030e-07 5.24581373e-01\n",
      "  5.65984010e-06 1.14406034e-01 1.66766620e-06 4.87819202e-02\n",
      "  8.03162905e-08 2.61456898e-05 8.68585630e-07 1.85876215e-05\n",
      "  1.13624878e-06 1.30208355e-04]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[2.1039504e-08 7.0607515e-09 5.0790038e-07 2.2343345e-09 1.3114612e-05\n",
      "  1.3652176e-08 5.6706790e-02 9.4665498e-05 9.9813044e-02 1.3873750e-05\n",
      "  1.1837912e-01 4.9917688e-08 1.1268614e-01 6.1159008e-05 9.3530275e-02\n",
      "  9.2265417e-08 1.6777374e-01 1.6292276e-08 2.9674748e-01 9.8088776e-07\n",
      "  5.4178867e-02 2.2331001e-08]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]  Prediction: [[7.19614536e-06 1.03803305e-02 5.34074134e-05 3.77311480e-05\n",
      "  2.54343875e-04 5.05182243e-07 3.05598817e-08 2.47414810e-05\n",
      "  1.24354882e-08 1.17124939e-04 1.62058381e-10 1.55225043e-05\n",
      "  4.86576880e-07 4.68052494e-05 6.23328802e-08 3.29425698e-03\n",
      "  2.11530065e-07 4.02181864e-01 4.27833724e-09 3.04458559e-01\n",
      "  7.54158191e-06 2.79119223e-01]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[7.0609327e-05 3.4860969e-01 2.4169240e-05 1.1190840e-03 3.2992961e-05\n",
      "  3.8924511e-03 1.1156756e-04 7.2618056e-04 1.4795334e-04 8.7148437e-06\n",
      "  9.1131762e-05 1.9635141e-03 3.7406303e-04 1.2226148e-04 5.7260548e-03\n",
      "  1.1076042e-02 1.2386421e-03 5.8451957e-01 8.8028231e-05 1.9941755e-02\n",
      "  1.4188006e-03 1.8696794e-02]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[2.37215102e-01 5.86724767e-08 1.81797892e-01 9.00773102e-06\n",
      "  1.28396228e-01 3.73807874e-09 8.31309990e-06 1.15040995e-01\n",
      "  2.53568694e-04 1.24098919e-01 4.79958453e-06 9.11972970e-02\n",
      "  6.62793218e-06 1.13564178e-01 8.15092491e-08 8.39186646e-03\n",
      "  2.60686846e-07 6.50316224e-07 2.68083977e-06 1.08635686e-06\n",
      "  1.00541320e-05 3.42520650e-07]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[9.4836531e-03 1.4046767e-01 2.6991619e-03 3.7135077e-01 2.2868142e-02\n",
      "  1.8500900e-04 4.1430862e-06 1.4596048e-02 5.4782206e-05 1.0084603e-02\n",
      "  3.3672386e-06 1.2998723e-02 4.1189342e-05 6.3024037e-02 2.0807967e-04\n",
      "  2.6817301e-01 3.4331166e-05 1.8641826e-02 6.2377359e-05 9.1900285e-03\n",
      "  6.3510837e-05 5.5765610e-02]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.20283908e-10 5.77097981e-10 1.12475149e-08 2.97263325e-11\n",
      "  1.39394061e-07 2.72820586e-11 1.38755292e-02 3.81276806e-07\n",
      "  4.62534964e-01 8.83372948e-08 1.93726588e-02 2.03408312e-09\n",
      "  3.57894123e-01 9.77566515e-07 2.25851350e-02 1.65856176e-10\n",
      "  1.13441095e-01 2.43818472e-11 6.44318759e-03 2.57632582e-08\n",
      "  3.85172036e-03 1.38388025e-11]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.75041035e-01 2.81519601e-06 9.62139145e-02 1.01146994e-04\n",
      "  1.69388860e-01 2.78294987e-08 1.04888204e-05 1.35760382e-01\n",
      "  1.86545018e-04 2.12268531e-01 2.55335954e-06 6.91136122e-02\n",
      "  3.81426707e-06 9.10950899e-02 1.51098141e-06 5.07718511e-02\n",
      "  7.06721380e-07 1.82743509e-06 1.74902798e-05 8.63743389e-06\n",
      "  5.13298528e-06 3.98044267e-06]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]  Prediction: [[1.85977574e-02 1.88982245e-02 2.24156249e-02 3.54501516e-01\n",
      "  6.36455268e-02 1.03567618e-05 1.00658599e-05 4.64364663e-02\n",
      "  2.89133222e-05 1.94713380e-02 6.20699041e-07 1.25179172e-01\n",
      "  9.05628985e-06 7.48926327e-02 9.75018611e-06 2.41619900e-01\n",
      "  1.25957888e-06 1.66611187e-03 1.06038415e-05 1.57161686e-03\n",
      "  8.07904144e-06 1.10153388e-02]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[6.1415335e-09 5.1737786e-10 1.7711602e-07 2.2046912e-10 5.7949551e-06\n",
      "  8.2466656e-10 4.5566663e-02 4.6480116e-05 1.1013765e-01 8.5032034e-06\n",
      "  1.2224662e-01 6.5107497e-09 1.5037028e-01 7.2594514e-05 5.1698834e-02\n",
      "  1.0776014e-08 9.8895475e-02 4.8929816e-10 3.4714335e-01 8.2451557e-08\n",
      "  7.3807493e-02 1.3345024e-09]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[8.25122595e-02 7.18213016e-07 3.64049047e-01 6.32592491e-05\n",
      "  1.36927754e-01 2.52523247e-08 4.18377167e-04 1.21035226e-01\n",
      "  1.78912445e-03 1.93611622e-01 1.12843023e-04 2.50888690e-02\n",
      "  1.26384039e-04 6.53473213e-02 4.81645611e-06 8.43347237e-03\n",
      "  7.54964321e-06 1.44515036e-06 1.80356510e-04 1.90421506e-05\n",
      "  2.67953990e-04 2.60010506e-06]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[3.45122628e-02 1.30609039e-03 3.48632224e-02 3.06350198e-02\n",
      "  1.02908403e-01 4.09456743e-06 1.59909814e-05 1.03564367e-01\n",
      "  3.54713520e-05 8.22956786e-02 1.42409340e-06 1.10158145e-01\n",
      "  5.74889100e-06 1.13063879e-01 2.61669220e-06 3.78828496e-01\n",
      "  5.12049155e-07 6.10979623e-04 5.70928478e-06 2.05388595e-03\n",
      "  7.88027046e-06 5.12003805e-03]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[4.9367244e-03 8.1079581e-04 6.3328701e-03 4.0692053e-04 2.1868441e-01\n",
      "  3.1395222e-05 2.5107475e-02 8.0838352e-02 9.9370070e-02 1.5486142e-01\n",
      "  1.7590042e-02 4.6614711e-03 5.0340302e-02 1.4609350e-01 1.5755506e-02\n",
      "  2.1477847e-03 1.6776159e-02 2.1387928e-04 1.3264406e-01 1.5519517e-03\n",
      "  1.9243291e-02 1.6016490e-03]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[5.46854473e-09 3.77725806e-09 7.99848465e-07 1.44467649e-09\n",
      "  1.01249748e-06 1.06518283e-09 1.01591386e-01 1.05358877e-05\n",
      "  9.55948234e-02 1.21995481e-06 2.95341350e-02 9.77378107e-08\n",
      "  4.58263457e-01 2.52093696e-06 3.12041994e-02 9.91978411e-08\n",
      "  2.22732827e-01 1.57724356e-09 2.83788927e-02 2.16415231e-07\n",
      "  3.26837562e-02 6.99038383e-10]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]  Prediction: [[4.0199529e-07 1.4277552e-07 1.3056572e-06 1.3247494e-08 1.9921214e-05\n",
      "  3.6426908e-08 1.3654305e-02 9.1595728e-05 6.3790403e-02 2.1819369e-05\n",
      "  6.4261086e-02 1.8393832e-06 1.3971351e-01 1.6290783e-04 1.9902979e-01\n",
      "  2.1390581e-06 1.0052223e-01 4.5950213e-07 3.6586633e-01 4.1143121e-06\n",
      "  5.2855495e-02 1.5010754e-07]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]  Prediction: [[3.2615289e-04 3.1925958e-02 3.8234843e-04 3.6882965e-03 1.0406509e-03\n",
      "  2.3537007e-06 8.7551678e-07 8.3628175e-04 1.0268778e-06 8.5936353e-04\n",
      "  1.3801879e-07 4.9776788e-04 7.7862433e-07 1.3137865e-03 2.0233765e-06\n",
      "  9.2553325e-02 9.2608030e-07 2.0411982e-01 6.5978651e-07 3.7200102e-01\n",
      "  5.8941450e-06 2.9044059e-01]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Answer: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]  Prediction: [[8.8640169e-05 4.6020817e-02 4.3064356e-05 3.4198218e-03 1.3635120e-04\n",
      "  5.5952628e-06 7.6634848e-08 1.3614824e-04 2.1042432e-08 4.9323218e-05\n",
      "  1.2067760e-08 1.8352593e-04 2.0342547e-07 2.3966249e-04 1.4786637e-07\n",
      "  1.4368531e-01 1.3722907e-07 1.5280518e-01 2.4635419e-08 3.5141236e-01\n",
      "  6.3559219e-07 3.0177289e-01]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  Prediction: [[8.8564487e-04 1.0228458e-01 1.8693958e-03 5.6967676e-01 1.3560746e-03\n",
      "  4.2843982e-05 4.9069450e-07 1.2618967e-02 6.7705702e-07 6.1510067e-04\n",
      "  1.7909183e-07 7.8077726e-03 9.0503784e-07 2.5358982e-03 4.4476592e-06\n",
      "  2.7364334e-01 2.8414689e-07 2.7364113e-03 1.7037241e-06 7.6575195e-03\n",
      "  7.0189844e-06 1.6253868e-02]]\n"
     ]
    }
   ],
   "source": [
    "# TEST: Load model and run it against test set\n",
    "model = models.load_model(model_filename)\n",
    "for i in range(1, 50):\n",
    "    print('Answer:', y_test[i], ' Prediction:', model.predict(np.expand_dims(x_test[i], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with test set\n",
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
