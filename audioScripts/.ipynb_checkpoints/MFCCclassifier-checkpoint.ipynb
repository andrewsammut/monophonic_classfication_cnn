{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "from tensorflow.keras import layers, models, utils\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A#3', 'A#4', 'A3', 'A4', 'B3', 'B4', 'C#3', 'C#4', 'C3', 'C4', 'D#3', 'D#4', 'D3', 'D4', 'E3', 'E4', 'F#3', 'F#4', 'F3', 'F4', 'G3', 'G4']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Create list of all targets (minus background noise)\n",
    "\n",
    "dataset_path = 'C:\\\\Users\\\\Greg\\\\ML\\\\Technical\\\\project\\\\git2\\\\monophonic_classfication_cnn\\\\padded'\n",
    "all_targets = all_targets = [name for name in listdir(dataset_path) if isdir(join(dataset_path, name))]\n",
    "all_targets.remove('_background_noise_')\n",
    "train_target = ['A3', 'A#3', 'B3', 'C3', 'C#3','D3', 'D#3', 'E3', 'F3', 'F#3','G3','A4']\n",
    "print(all_targets)\n",
    "numclasses = len(train_target)\n",
    "print(numclasses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "feature_sets_path = 'C:\\\\Users\\\\Greg\\\\ML\\\\Technical\\\\project\\\\git2\\\\monophonic_classfication_cnn\\\\audioScripts'\n",
    "feature_sets_filename = 'all_targets_mfcc_sets.npz'\n",
    "model_filename = 'AudioModel.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "# Load feature sets\n",
    "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\n",
    "print(feature_sets.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 16, 16)\n",
      "(64, 16, 16)\n",
      "(64, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "# Look at tensor dimensions\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  8. 10.  8.  7. 10.  4.  5.  1.  1.  0.  6.  5.  8.  2.  0.  0. 11.\n",
      " 11.  7. 11. 11. 11. 10.  6. 10.  4.  5.  7.  4.  5.  1.  2.  0.  7.  5.\n",
      "  8.  7.  7.  3.  4.  1.  0.  9.  5. 10.  1. 10.  9.  6.  9.  7.  0.  1.\n",
      "  4.  2.  0.  8.  0.  2.  1.  2.  6.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Peek at labels\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ground truth arrays to one wake word (1) and 'other' (0)\n",
    "#ytr = []\n",
    "#yv = []\n",
    "#yts = []\n",
    "#count = 1\n",
    "#for pitch in all_targets:\n",
    "#    pitch_index = all_targets.index(pitch)\n",
    "#    ytr.append(np.equal(y_train, pitch_index).astype('float64'))\n",
    "#    yv.append( np.equal(y_val, pitch_index).astype('float64'))\n",
    "#    yts.append(np.equal(y_test, pitch_index).astype('float64'))\n",
    "    #count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.  1. 10.  7.  7. 11.  7.  1.  1.  4.  7.  6.  3.  2. 11.  9. 11. 10.\n",
      "  5.  8.  9. 10.  7.  8. 10.  5.  5.  7.  4.  9.  4.  6.  5.  5.  5.  4.\n",
      " 10. 11. 11.  2.  6. 10.  6.  5.  9.  3.  2.  4.  8. 11.  0.  1.  2. 11.\n",
      "  9.  2.  4.  2.  2. 11.  4. 10.  0.  7.  3.  5.  8.  1.  1.  1. 10.  6.\n",
      "  4. 10.  1.  5. 11.  4.  8. 10.  8. 11.  6.  2. 10.  9.  0.  7. 10.  2.\n",
      " 10.  1.  7.  8. 11.  3.  2.  2. 11.  3.  7.  5.  9.  6.  0.  2. 10.  7.\n",
      "  0.  1.  2.  0.  7.  5.  1.  2. 10.  6.  1. 10.  9.  0. 11.  6.  3. 10.\n",
      " 10.  6.  0.  7.  1.  0.  9.  7.  8.  0.  9.  3.  8. 10.  7.  9. 10. 11.\n",
      " 11.  0.  4. 11.  4.  1.  4.  7.  5.  2.  6.  1.  1.  6.  8.  9. 10.  3.\n",
      "  2.  2. 10.  2.  2.  6.  6.  5.  3.  7.  8. 10.  5.  3.  6.  1. 10.  0.\n",
      "  1. 11.  0.  5.  9.  5.  9.  3.  0. 10.  4.  8.  0. 10.  2.  9.  5. 10.\n",
      "  2.  9.  8.  7.  3.  6.  9.  2.  6.  8.  2.  1. 10.  1. 10.  0.  8.  5.\n",
      "  8.  6.  8.  6.  9.  2.  8. 11.  4.  9.  3.  1.  0.  2.  7.  4.  6. 11.\n",
      "  2.  7.  6.  6.  6.  3.  5.  4. 10.  1.  6. 10.  6. 11.  2. 10.  8.  2.\n",
      " 10. 11.  9.  9.  0.  6.  8. 10.  5.  7.  9. 10.  0.  7.  5. 11. 10.  9.\n",
      "  8.  3.  7.  5.  5.  1.  7.  0.  2.  8.  7.  8.  1. 11.  9.  2.  9.  4.\n",
      "  4.  5.  5. 11.  1.  7.  0. 10. 10.  1.  6.  4.  7.  7. 11.  2. 11.  2.\n",
      "  7.  0.  8.  1.  9. 11.  0.  2.  9.  8.  8.  1.  4.  4.  7.  3.  6.  2.\n",
      "  0.  4.  7. 11.  0. 10.  5. 11.  3.  9. 10.  4. 10.  5.  5.  9.  5.  3.\n",
      "  7.  2.  4.  2.  3.  2.  9.  4.  2.  1.  8. 11. 10.  7.  8.  0.  1.  4.\n",
      "  9.  1.  2.  1.  3.  4.  7.  9.  3. 11.  4.  0.  9.  5.  3.  9.  2. 11.\n",
      "  4.  1. 11.  7.  1. 11. 10. 11.  7.  6.  5.  7.  3.  4.  3.  9.  0.  1.\n",
      " 11. 11.  5.  5. 11.  2.  0.  6.  4.  7.  3.  6.  8.  3.  2.  2.  8.  4.\n",
      "  6.  9.  0.  3.  3.  1.  1.  6.  0.  9.  0.  0.  8. 11.  3.  1.  3.  0.\n",
      "  0.  3.  9.  7.  8.  6.  2.  0.  8.  9.  6.  1.  8. 11.  0. 10.  0.  1.\n",
      " 11.  4.  9.  1. 10.  4. 11.  2.  0.  1.  6.  1.  0.  7. 11.  6.  8.  9.\n",
      "  4.  5.  1. 11.  5.  6. 11.  8.  8. 11.  1.  9.  6. 10.  0. 11.  1.  5.\n",
      "  1. 11.  8.  0.  0.  0.  5.  2.  1. 10.  3.  6. 10.  2.  2. 11. 11.  0.\n",
      "  1.  3.  2.  0.  2.  0.  8.  0. 11.  3.  3.  5.]\n"
     ]
    }
   ],
   "source": [
    "# Peek at labels after conversion\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentage of 'stop' appear in validation labels\n",
    "#print(sum(y_val) / len(y_val))\n",
    "#print(1 - sum(y_val) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dimensions of our input data\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 16, 16, 1)\n",
      "(64, 16, 16, 1)\n",
      "(64, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN for TF expects (batch, height, width, channels)\n",
    "# So we reshape the input tensors with a \"color\" channel of 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "#y_train = utils.to_categorical(y_train, numclasses)\n",
    "#y_test = utils.to_categorical(y_test, numclasses)\n",
    "#y_val = utils.to_categorical(y_val, numclasses)\n",
    "\n",
    "#fig=plt.figure()\n",
    "#plt.imshow(x_val[11], cmap='inferno', origin='lower')\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Input shape for CNN is size of MFCC of 1 sample\n",
    "sample_shape = x_test.shape[1:]\n",
    "print(sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "# Based on: https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, 2, activation='relu',input_shape=sample_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(numclasses, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 64)          8256      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,124\n",
      "Trainable params: 46,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training parameters to model\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 2s 202ms/step - loss: 3.2517 - acc: 0.0795 - val_loss: 2.6348 - val_acc: 0.0781\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 2.4901 - acc: 0.1279 - val_loss: 2.3535 - val_acc: 0.1094\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 2.3209 - acc: 0.1764 - val_loss: 2.2387 - val_acc: 0.1719\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.2055 - acc: 0.2112 - val_loss: 2.1345 - val_acc: 0.1719\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 2.0698 - acc: 0.2461 - val_loss: 2.1019 - val_acc: 0.2188\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 1.9680 - acc: 0.2810 - val_loss: 2.0447 - val_acc: 0.2344\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 1.8936 - acc: 0.2791 - val_loss: 2.0098 - val_acc: 0.1875\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 1.8200 - acc: 0.2907 - val_loss: 1.9764 - val_acc: 0.2031\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.7854 - acc: 0.3043 - val_loss: 1.9262 - val_acc: 0.2969\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 1.8091 - acc: 0.3004 - val_loss: 1.9335 - val_acc: 0.1875\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.7361 - acc: 0.3411 - val_loss: 1.9302 - val_acc: 0.2812\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.7236 - acc: 0.3411 - val_loss: 1.9318 - val_acc: 0.1719\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.6722 - acc: 0.3391 - val_loss: 1.8493 - val_acc: 0.2969\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.6663 - acc: 0.3702 - val_loss: 1.8458 - val_acc: 0.2812\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.6169 - acc: 0.3740 - val_loss: 1.8978 - val_acc: 0.2344\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.6159 - acc: 0.3779 - val_loss: 1.8441 - val_acc: 0.2812\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.5787 - acc: 0.3915 - val_loss: 1.8485 - val_acc: 0.2656\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.5665 - acc: 0.3895 - val_loss: 1.9064 - val_acc: 0.2656\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.5803 - acc: 0.3605 - val_loss: 1.8283 - val_acc: 0.2500\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.5289 - acc: 0.4089 - val_loss: 1.8337 - val_acc: 0.2500\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.5157 - acc: 0.4264 - val_loss: 1.8657 - val_acc: 0.2812\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.4910 - acc: 0.4360 - val_loss: 1.8467 - val_acc: 0.2812\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.4635 - acc: 0.4632 - val_loss: 1.8158 - val_acc: 0.2500\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.4841 - acc: 0.4399 - val_loss: 1.8070 - val_acc: 0.3125\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.4500 - acc: 0.4612 - val_loss: 1.7854 - val_acc: 0.2969\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.4542 - acc: 0.4535 - val_loss: 1.7805 - val_acc: 0.3281\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.4156 - acc: 0.4748 - val_loss: 1.8200 - val_acc: 0.3125\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.4062 - acc: 0.4787 - val_loss: 1.7969 - val_acc: 0.3438\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.4009 - acc: 0.4806 - val_loss: 1.7959 - val_acc: 0.3125\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.4040 - acc: 0.4612 - val_loss: 1.8044 - val_acc: 0.3438\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.3817 - acc: 0.4806 - val_loss: 1.7514 - val_acc: 0.3438\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.3635 - acc: 0.4903 - val_loss: 1.7589 - val_acc: 0.3594\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.3476 - acc: 0.5058 - val_loss: 1.7886 - val_acc: 0.3438\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.3231 - acc: 0.5058 - val_loss: 1.8245 - val_acc: 0.3281\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.3409 - acc: 0.5097 - val_loss: 1.8175 - val_acc: 0.3438\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.3051 - acc: 0.5271 - val_loss: 1.8223 - val_acc: 0.3281\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.3331 - acc: 0.4709 - val_loss: 1.7909 - val_acc: 0.3438\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.3448 - acc: 0.4845 - val_loss: 1.8301 - val_acc: 0.2969\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.3992 - acc: 0.4884 - val_loss: 1.9093 - val_acc: 0.2500\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.3337 - acc: 0.4961 - val_loss: 1.8358 - val_acc: 0.3594\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.3171 - acc: 0.5039 - val_loss: 1.8317 - val_acc: 0.3438\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.2787 - acc: 0.5388 - val_loss: 1.7665 - val_acc: 0.3594\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 1.2841 - acc: 0.5310 - val_loss: 1.7876 - val_acc: 0.3750\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.2751 - acc: 0.5271 - val_loss: 1.7294 - val_acc: 0.3594\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.2456 - acc: 0.5407 - val_loss: 1.7731 - val_acc: 0.3906\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.1899 - acc: 0.5814 - val_loss: 1.7486 - val_acc: 0.3594\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.1799 - acc: 0.5814 - val_loss: 1.7699 - val_acc: 0.3594\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.1799 - acc: 0.5775 - val_loss: 1.7327 - val_acc: 0.3594\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.1626 - acc: 0.5930 - val_loss: 1.7792 - val_acc: 0.3906\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1429 - acc: 0.5795 - val_loss: 1.7638 - val_acc: 0.3594\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1353 - acc: 0.6066 - val_loss: 1.7823 - val_acc: 0.3438\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.1052 - acc: 0.6027 - val_loss: 1.7819 - val_acc: 0.3750\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0990 - acc: 0.6260 - val_loss: 1.8452 - val_acc: 0.3750\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0904 - acc: 0.6066 - val_loss: 1.7488 - val_acc: 0.3438\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.1167 - acc: 0.6085 - val_loss: 1.9127 - val_acc: 0.3125\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.0677 - acc: 0.6182 - val_loss: 1.8255 - val_acc: 0.3906\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.0458 - acc: 0.6182 - val_loss: 1.7382 - val_acc: 0.4219\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.0566 - acc: 0.6085 - val_loss: 1.7613 - val_acc: 0.4219\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.0180 - acc: 0.6376 - val_loss: 1.7731 - val_acc: 0.3750\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9842 - acc: 0.6667 - val_loss: 1.8186 - val_acc: 0.3594\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0165 - acc: 0.6376 - val_loss: 1.8842 - val_acc: 0.3750\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0052 - acc: 0.6550 - val_loss: 1.7254 - val_acc: 0.4219\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9778 - acc: 0.6492 - val_loss: 1.8415 - val_acc: 0.4219\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9536 - acc: 0.6822 - val_loss: 1.7823 - val_acc: 0.4062\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9724 - acc: 0.6434 - val_loss: 1.8111 - val_acc: 0.3594\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9702 - acc: 0.6570 - val_loss: 1.8880 - val_acc: 0.3594\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9311 - acc: 0.6609 - val_loss: 1.8151 - val_acc: 0.3594\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9597 - acc: 0.6647 - val_loss: 1.8315 - val_acc: 0.3750\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9302 - acc: 0.6667 - val_loss: 1.8320 - val_acc: 0.4062\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9012 - acc: 0.6957 - val_loss: 1.7948 - val_acc: 0.4219\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8493 - acc: 0.7267 - val_loss: 1.8488 - val_acc: 0.4062\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.8762 - acc: 0.7074 - val_loss: 1.9130 - val_acc: 0.3750\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8661 - acc: 0.7190 - val_loss: 1.7884 - val_acc: 0.4375\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.9174 - acc: 0.6609 - val_loss: 1.9239 - val_acc: 0.3594\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8870 - acc: 0.6880 - val_loss: 1.8384 - val_acc: 0.4062\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.8756 - acc: 0.6783 - val_loss: 1.8429 - val_acc: 0.3750\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8621 - acc: 0.7054 - val_loss: 1.9000 - val_acc: 0.4062\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8520 - acc: 0.6899 - val_loss: 1.9103 - val_acc: 0.3906\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.8197 - acc: 0.7171 - val_loss: 1.9552 - val_acc: 0.3750\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8331 - acc: 0.6977 - val_loss: 1.8754 - val_acc: 0.4219\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.7868 - acc: 0.7229 - val_loss: 1.9884 - val_acc: 0.3906\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.8315 - acc: 0.7171 - val_loss: 1.9073 - val_acc: 0.4219\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.7636 - acc: 0.7384 - val_loss: 1.9582 - val_acc: 0.3906\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.7577 - acc: 0.7422 - val_loss: 1.8693 - val_acc: 0.4375\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.7075 - acc: 0.7752 - val_loss: 1.8736 - val_acc: 0.4375\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6901 - acc: 0.7888 - val_loss: 1.9196 - val_acc: 0.4531\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.6751 - acc: 0.8198 - val_loss: 1.8907 - val_acc: 0.4062\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6555 - acc: 0.8198 - val_loss: 1.8932 - val_acc: 0.4375\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6704 - acc: 0.7791 - val_loss: 2.0003 - val_acc: 0.4219\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.6703 - acc: 0.7752 - val_loss: 1.9938 - val_acc: 0.4219\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.6707 - acc: 0.7655 - val_loss: 2.0054 - val_acc: 0.3906\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.6813 - acc: 0.7791 - val_loss: 1.9072 - val_acc: 0.3906\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6630 - acc: 0.7791 - val_loss: 1.9496 - val_acc: 0.4062\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.6315 - acc: 0.7926 - val_loss: 1.9888 - val_acc: 0.4219\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.6494 - acc: 0.7907 - val_loss: 1.9593 - val_acc: 0.4062\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.6223 - acc: 0.8256 - val_loss: 2.0215 - val_acc: 0.4062\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.6458 - acc: 0.7771 - val_loss: 2.0773 - val_acc: 0.4062\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.6600 - acc: 0.7578 - val_loss: 1.9963 - val_acc: 0.3750\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6278 - acc: 0.7829 - val_loss: 2.0822 - val_acc: 0.3750\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.6796 - acc: 0.7829 - val_loss: 2.1225 - val_acc: 0.3125\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.7044 - acc: 0.7558 - val_loss: 2.0263 - val_acc: 0.4062\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6089 - acc: 0.8023 - val_loss: 2.0168 - val_acc: 0.4062\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.6735 - acc: 0.7578 - val_loss: 2.1126 - val_acc: 0.4375\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.6178 - acc: 0.7849 - val_loss: 1.8846 - val_acc: 0.4219\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.5914 - acc: 0.8062 - val_loss: 2.0533 - val_acc: 0.3750\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.5744 - acc: 0.8236 - val_loss: 1.9981 - val_acc: 0.4219\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5625 - acc: 0.8198 - val_loss: 1.9925 - val_acc: 0.4062\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.6032 - acc: 0.7829 - val_loss: 2.0908 - val_acc: 0.3906\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.5803 - acc: 0.8140 - val_loss: 2.0184 - val_acc: 0.4062\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.5556 - acc: 0.8043 - val_loss: 2.0977 - val_acc: 0.3594\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.5334 - acc: 0.8198 - val_loss: 2.0829 - val_acc: 0.3906\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.5304 - acc: 0.8353 - val_loss: 2.0667 - val_acc: 0.4062\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.5165 - acc: 0.8547 - val_loss: 2.1588 - val_acc: 0.3750\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.4870 - acc: 0.8585 - val_loss: 2.2323 - val_acc: 0.3906\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.4628 - acc: 0.8702 - val_loss: 2.0352 - val_acc: 0.4062\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.4425 - acc: 0.8876 - val_loss: 2.1837 - val_acc: 0.3438\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.4665 - acc: 0.8663 - val_loss: 2.1168 - val_acc: 0.4219\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.4418 - acc: 0.8605 - val_loss: 2.3639 - val_acc: 0.3438\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4826 - acc: 0.8372 - val_loss: 2.2983 - val_acc: 0.3906\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.5477 - acc: 0.8081 - val_loss: 2.4183 - val_acc: 0.3438\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.5038 - acc: 0.8411 - val_loss: 2.3811 - val_acc: 0.3594\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.4622 - acc: 0.8779 - val_loss: 2.4004 - val_acc: 0.3281\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.4581 - acc: 0.8585 - val_loss: 2.3310 - val_acc: 0.3750\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.4106 - acc: 0.8876 - val_loss: 2.2834 - val_acc: 0.3594\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.3930 - acc: 0.9050 - val_loss: 2.1765 - val_acc: 0.4062\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.3557 - acc: 0.9167 - val_loss: 2.2319 - val_acc: 0.3438\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.3552 - acc: 0.9167 - val_loss: 2.2751 - val_acc: 0.3906\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.3482 - acc: 0.9167 - val_loss: 2.2690 - val_acc: 0.3906\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3226 - acc: 0.9419 - val_loss: 2.2550 - val_acc: 0.3750\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3467 - acc: 0.9186 - val_loss: 2.2105 - val_acc: 0.4219\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3990 - acc: 0.8663 - val_loss: 2.2808 - val_acc: 0.3750\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3573 - acc: 0.8895 - val_loss: 2.3843 - val_acc: 0.3750\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.3352 - acc: 0.9167 - val_loss: 2.3013 - val_acc: 0.4219\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3330 - acc: 0.9205 - val_loss: 2.2548 - val_acc: 0.4062\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3342 - acc: 0.9050 - val_loss: 2.2815 - val_acc: 0.4375\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3058 - acc: 0.9283 - val_loss: 2.3382 - val_acc: 0.3906\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.3046 - acc: 0.9205 - val_loss: 2.2496 - val_acc: 0.4062\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2919 - acc: 0.9419 - val_loss: 2.2604 - val_acc: 0.4219\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2883 - acc: 0.9302 - val_loss: 2.4000 - val_acc: 0.4062\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.3067 - acc: 0.9147 - val_loss: 2.4728 - val_acc: 0.3906\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.3142 - acc: 0.9128 - val_loss: 2.4956 - val_acc: 0.4062\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2830 - acc: 0.9438 - val_loss: 2.4755 - val_acc: 0.3750\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2772 - acc: 0.9438 - val_loss: 2.3944 - val_acc: 0.3594\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2958 - acc: 0.9050 - val_loss: 2.5426 - val_acc: 0.3750\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.2755 - acc: 0.9322 - val_loss: 2.4596 - val_acc: 0.4062\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.2572 - acc: 0.9438 - val_loss: 2.3925 - val_acc: 0.3750\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.2448 - acc: 0.9554 - val_loss: 2.4800 - val_acc: 0.4062\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.2332 - acc: 0.9457 - val_loss: 2.5049 - val_acc: 0.3906\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.2298 - acc: 0.9593 - val_loss: 2.5202 - val_acc: 0.4062\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.2100 - acc: 0.9632 - val_loss: 2.5179 - val_acc: 0.3906\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.2282 - acc: 0.9554 - val_loss: 2.5508 - val_acc: 0.3750\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2345 - acc: 0.9516 - val_loss: 2.5892 - val_acc: 0.3750\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2223 - acc: 0.9574 - val_loss: 2.5072 - val_acc: 0.4375\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2155 - acc: 0.9574 - val_loss: 2.6068 - val_acc: 0.3906\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2287 - acc: 0.9516 - val_loss: 2.6256 - val_acc: 0.3438\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2073 - acc: 0.9651 - val_loss: 2.6221 - val_acc: 0.3281\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2069 - acc: 0.9593 - val_loss: 2.7015 - val_acc: 0.3750\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.2139 - acc: 0.9593 - val_loss: 2.6535 - val_acc: 0.3438\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2078 - acc: 0.9535 - val_loss: 2.7880 - val_acc: 0.3906\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2135 - acc: 0.9496 - val_loss: 2.8271 - val_acc: 0.3594\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2191 - acc: 0.9457 - val_loss: 2.8818 - val_acc: 0.3750\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.2403 - acc: 0.9264 - val_loss: 2.6644 - val_acc: 0.4062\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.2009 - acc: 0.9709 - val_loss: 2.6550 - val_acc: 0.3438\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.1759 - acc: 0.9671 - val_loss: 2.9398 - val_acc: 0.3438\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.1824 - acc: 0.9671 - val_loss: 2.8089 - val_acc: 0.4062\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1720 - acc: 0.9690 - val_loss: 2.7468 - val_acc: 0.3438\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1824 - acc: 0.9671 - val_loss: 2.8107 - val_acc: 0.3281\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.1561 - acc: 0.9748 - val_loss: 2.7841 - val_acc: 0.3594\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.1734 - acc: 0.9632 - val_loss: 2.7701 - val_acc: 0.3594\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1773 - acc: 0.9612 - val_loss: 2.9499 - val_acc: 0.3594\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1816 - acc: 0.9593 - val_loss: 2.7474 - val_acc: 0.4062\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1651 - acc: 0.9690 - val_loss: 2.7422 - val_acc: 0.3906\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1537 - acc: 0.9690 - val_loss: 2.9031 - val_acc: 0.3594\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1472 - acc: 0.9767 - val_loss: 2.8479 - val_acc: 0.4062\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1424 - acc: 0.9787 - val_loss: 2.7556 - val_acc: 0.3594\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1599 - acc: 0.9574 - val_loss: 2.9800 - val_acc: 0.3594\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1907 - acc: 0.9477 - val_loss: 2.8693 - val_acc: 0.3281\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1494 - acc: 0.9671 - val_loss: 2.9990 - val_acc: 0.3750\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1197 - acc: 0.9845 - val_loss: 2.8872 - val_acc: 0.3594\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1197 - acc: 0.9806 - val_loss: 2.9531 - val_acc: 0.3594\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.1153 - acc: 0.9864 - val_loss: 2.8489 - val_acc: 0.3750\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1047 - acc: 0.9903 - val_loss: 2.8520 - val_acc: 0.3750\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1164 - acc: 0.9903 - val_loss: 2.9698 - val_acc: 0.3750\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1140 - acc: 0.9903 - val_loss: 2.9407 - val_acc: 0.3438\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0987 - acc: 0.9922 - val_loss: 2.9889 - val_acc: 0.3906\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1082 - acc: 0.9806 - val_loss: 2.9846 - val_acc: 0.4062\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.1064 - acc: 0.9922 - val_loss: 2.9147 - val_acc: 0.4219\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1118 - acc: 0.9864 - val_loss: 3.0562 - val_acc: 0.3906\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1225 - acc: 0.9806 - val_loss: 3.0601 - val_acc: 0.3906\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1337 - acc: 0.9845 - val_loss: 3.0818 - val_acc: 0.3906\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1174 - acc: 0.9826 - val_loss: 3.1397 - val_acc: 0.3594\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1065 - acc: 0.9787 - val_loss: 2.9503 - val_acc: 0.4375\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1113 - acc: 0.9787 - val_loss: 3.0658 - val_acc: 0.3438\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1057 - acc: 0.9806 - val_loss: 3.2378 - val_acc: 0.3438\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1198 - acc: 0.9748 - val_loss: 3.1166 - val_acc: 0.3750\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0913 - acc: 0.9903 - val_loss: 3.1587 - val_acc: 0.3906\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0937 - acc: 0.9864 - val_loss: 3.2131 - val_acc: 0.3125\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1084 - acc: 0.9864 - val_loss: 3.1255 - val_acc: 0.3750\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0886 - acc: 0.9864 - val_loss: 3.2384 - val_acc: 0.3906\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0895 - acc: 0.9884 - val_loss: 3.1463 - val_acc: 0.3906\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0990 - acc: 0.9864 - val_loss: 3.1372 - val_acc: 0.3750\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0841 - acc: 0.9981 - val_loss: 3.2820 - val_acc: 0.4062\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1170 - acc: 0.9826 - val_loss: 3.2071 - val_acc: 0.3906\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0893 - acc: 0.9884 - val_loss: 3.1583 - val_acc: 0.3125\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0903 - acc: 0.9864 - val_loss: 3.1728 - val_acc: 0.3281\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0880 - acc: 0.9845 - val_loss: 3.1812 - val_acc: 0.3594\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0697 - acc: 0.9961 - val_loss: 3.1803 - val_acc: 0.3594\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0630 - acc: 0.9961 - val_loss: 3.2684 - val_acc: 0.3750\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0548 - acc: 0.9981 - val_loss: 3.2094 - val_acc: 0.3594\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0519 - acc: 1.0000 - val_loss: 3.1965 - val_acc: 0.3906\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0522 - acc: 0.9981 - val_loss: 3.2484 - val_acc: 0.4062\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0579 - acc: 0.9981 - val_loss: 3.2705 - val_acc: 0.3750\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0524 - acc: 0.9961 - val_loss: 3.2645 - val_acc: 0.3438\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0536 - acc: 1.0000 - val_loss: 3.3110 - val_acc: 0.3750\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0521 - acc: 0.9961 - val_loss: 3.3567 - val_acc: 0.3750\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0503 - acc: 0.9981 - val_loss: 3.3083 - val_acc: 0.3594\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0529 - acc: 0.9942 - val_loss: 3.3441 - val_acc: 0.3125\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0482 - acc: 0.9981 - val_loss: 3.3744 - val_acc: 0.3750\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0482 - acc: 0.9961 - val_loss: 3.3536 - val_acc: 0.3125\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0433 - acc: 1.0000 - val_loss: 3.3897 - val_acc: 0.3438\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0433 - acc: 0.9981 - val_loss: 3.3908 - val_acc: 0.3906\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0433 - acc: 0.9981 - val_loss: 3.4360 - val_acc: 0.3750\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0558 - acc: 0.9942 - val_loss: 3.4063 - val_acc: 0.3594\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0442 - acc: 0.9981 - val_loss: 3.3685 - val_acc: 0.3906\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0441 - acc: 0.9961 - val_loss: 3.3486 - val_acc: 0.3750\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0675 - acc: 0.9864 - val_loss: 3.5932 - val_acc: 0.3594\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1453 - acc: 0.9554 - val_loss: 3.4997 - val_acc: 0.4062\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0900 - acc: 0.9826 - val_loss: 3.3856 - val_acc: 0.3906\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0720 - acc: 0.9884 - val_loss: 3.5909 - val_acc: 0.3906\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0764 - acc: 0.9884 - val_loss: 3.6226 - val_acc: 0.3750\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0652 - acc: 0.9961 - val_loss: 3.5079 - val_acc: 0.3594\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0556 - acc: 0.9961 - val_loss: 3.5640 - val_acc: 0.3438\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0543 - acc: 0.9942 - val_loss: 3.6224 - val_acc: 0.3750\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0424 - acc: 0.9981 - val_loss: 3.4902 - val_acc: 0.3438\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0413 - acc: 0.9981 - val_loss: 3.6267 - val_acc: 0.3750\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0388 - acc: 1.0000 - val_loss: 3.6278 - val_acc: 0.3750\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0344 - acc: 1.0000 - val_loss: 3.5979 - val_acc: 0.3750\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0329 - acc: 1.0000 - val_loss: 3.5967 - val_acc: 0.3906\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0319 - acc: 1.0000 - val_loss: 3.5968 - val_acc: 0.3750\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 3.5758 - val_acc: 0.3906\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 3.6153 - val_acc: 0.4062\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0295 - acc: 1.0000 - val_loss: 3.6200 - val_acc: 0.3594\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0282 - acc: 1.0000 - val_loss: 3.6303 - val_acc: 0.3906\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0280 - acc: 1.0000 - val_loss: 3.6507 - val_acc: 0.3750\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0284 - acc: 0.9981 - val_loss: 3.6642 - val_acc: 0.3750\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0297 - acc: 1.0000 - val_loss: 3.6830 - val_acc: 0.3750\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0268 - acc: 1.0000 - val_loss: 3.6750 - val_acc: 0.3906\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0287 - acc: 1.0000 - val_loss: 3.6366 - val_acc: 0.3594\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0267 - acc: 1.0000 - val_loss: 3.7337 - val_acc: 0.3750\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0330 - acc: 0.9981 - val_loss: 3.7620 - val_acc: 0.3594\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0298 - acc: 0.9981 - val_loss: 3.6662 - val_acc: 0.3594\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0277 - acc: 1.0000 - val_loss: 3.6496 - val_acc: 0.3594\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 3.6915 - val_acc: 0.3750\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0266 - acc: 1.0000 - val_loss: 3.7724 - val_acc: 0.3594\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0294 - acc: 0.9981 - val_loss: 3.8048 - val_acc: 0.3594\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0308 - acc: 0.9981 - val_loss: 3.8548 - val_acc: 0.3438\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 3.7941 - val_acc: 0.3594\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0271 - acc: 1.0000 - val_loss: 3.9551 - val_acc: 0.3750\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0309 - acc: 0.9961 - val_loss: 3.8018 - val_acc: 0.3906\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0236 - acc: 1.0000 - val_loss: 3.8626 - val_acc: 0.3750\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0259 - acc: 0.9981 - val_loss: 3.8445 - val_acc: 0.3750\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 3.9034 - val_acc: 0.3594\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0235 - acc: 1.0000 - val_loss: 3.8653 - val_acc: 0.3750\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0218 - acc: 1.0000 - val_loss: 3.8438 - val_acc: 0.3594\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0227 - acc: 1.0000 - val_loss: 3.8141 - val_acc: 0.3594\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0226 - acc: 0.9981 - val_loss: 3.8675 - val_acc: 0.3594\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0205 - acc: 1.0000 - val_loss: 3.9319 - val_acc: 0.3438\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 3.8997 - val_acc: 0.3594\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 3.8946 - val_acc: 0.3438\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0184 - acc: 1.0000 - val_loss: 3.8907 - val_acc: 0.3438\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0180 - acc: 1.0000 - val_loss: 3.8979 - val_acc: 0.3438\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 3.9291 - val_acc: 0.3438\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 3.9302 - val_acc: 0.3594\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 3.9120 - val_acc: 0.3906\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 3.9295 - val_acc: 0.3594\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 3.9490 - val_acc: 0.3750\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0184 - acc: 1.0000 - val_loss: 3.9125 - val_acc: 0.3750\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 3.9605 - val_acc: 0.3594\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0190 - acc: 0.9981 - val_loss: 3.9852 - val_acc: 0.3750\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 3.9993 - val_acc: 0.3750\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0244 - acc: 0.9981 - val_loss: 4.0771 - val_acc: 0.3438\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0245 - acc: 0.9961 - val_loss: 3.9970 - val_acc: 0.3906\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0237 - acc: 1.0000 - val_loss: 4.0294 - val_acc: 0.3750\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0201 - acc: 0.9981 - val_loss: 4.0039 - val_acc: 0.3750\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0182 - acc: 1.0000 - val_loss: 4.0415 - val_acc: 0.3750\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0207 - acc: 0.9981 - val_loss: 3.9629 - val_acc: 0.3906\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0186 - acc: 0.9981 - val_loss: 4.0448 - val_acc: 0.3906\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 4.1217 - val_acc: 0.3750\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0171 - acc: 1.0000 - val_loss: 4.1256 - val_acc: 0.3438\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 4.0861 - val_acc: 0.3594\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 4.0870 - val_acc: 0.3750\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0175 - acc: 1.0000 - val_loss: 4.1027 - val_acc: 0.3594\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0193 - acc: 0.9981 - val_loss: 4.1824 - val_acc: 0.3750\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 4.1165 - val_acc: 0.3594\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 4.1037 - val_acc: 0.3750\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0224 - acc: 0.9961 - val_loss: 4.0509 - val_acc: 0.3906\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0266 - acc: 0.9922 - val_loss: 4.2285 - val_acc: 0.3594\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0414 - acc: 0.9845 - val_loss: 4.1410 - val_acc: 0.3750\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0801 - acc: 0.9748 - val_loss: 4.2439 - val_acc: 0.3594\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0663 - acc: 0.9845 - val_loss: 4.1718 - val_acc: 0.3281\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.1022 - acc: 0.9651 - val_loss: 4.3408 - val_acc: 0.3750\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.1878 - acc: 0.9477 - val_loss: 4.3115 - val_acc: 0.3906\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.2774 - acc: 0.9147 - val_loss: 4.5993 - val_acc: 0.3125\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2487 - acc: 0.9205 - val_loss: 4.2614 - val_acc: 0.3594\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.2183 - acc: 0.9322 - val_loss: 4.3935 - val_acc: 0.3594\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.2087 - acc: 0.9225 - val_loss: 4.1354 - val_acc: 0.3281\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3290 - acc: 0.9012 - val_loss: 4.4994 - val_acc: 0.3281\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1763 - acc: 0.9496 - val_loss: 4.9217 - val_acc: 0.2969\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1938 - acc: 0.9360 - val_loss: 4.4937 - val_acc: 0.3906\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1488 - acc: 0.9496 - val_loss: 4.7571 - val_acc: 0.2812\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1826 - acc: 0.9341 - val_loss: 4.3321 - val_acc: 0.4062\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1790 - acc: 0.9380 - val_loss: 4.5234 - val_acc: 0.3438\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1638 - acc: 0.9496 - val_loss: 4.1702 - val_acc: 0.3750\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1141 - acc: 0.9690 - val_loss: 4.0604 - val_acc: 0.3438\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1128 - acc: 0.9826 - val_loss: 4.3106 - val_acc: 0.2969\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1180 - acc: 0.9574 - val_loss: 4.2075 - val_acc: 0.3750\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0730 - acc: 0.9864 - val_loss: 4.3234 - val_acc: 0.3125\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0635 - acc: 0.9826 - val_loss: 4.3426 - val_acc: 0.3125\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0704 - acc: 0.9845 - val_loss: 4.5050 - val_acc: 0.2969\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0510 - acc: 0.9922 - val_loss: 4.4041 - val_acc: 0.3438\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0438 - acc: 0.9922 - val_loss: 4.3254 - val_acc: 0.3125\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0351 - acc: 0.9922 - val_loss: 4.1866 - val_acc: 0.3438\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0249 - acc: 0.9981 - val_loss: 4.0979 - val_acc: 0.3281\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0222 - acc: 0.9981 - val_loss: 4.2003 - val_acc: 0.3281\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0268 - acc: 0.9961 - val_loss: 4.2725 - val_acc: 0.3750\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0226 - acc: 0.9961 - val_loss: 4.2428 - val_acc: 0.3594\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0275 - acc: 0.9981 - val_loss: 4.2655 - val_acc: 0.3125\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0196 - acc: 0.9981 - val_loss: 4.2809 - val_acc: 0.3438\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 4.2799 - val_acc: 0.3438\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 4.2238 - val_acc: 0.3281\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 4.1861 - val_acc: 0.3438\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 4.1917 - val_acc: 0.3594\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 4.2203 - val_acc: 0.3281\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 4.2765 - val_acc: 0.3438\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0193 - acc: 0.9961 - val_loss: 4.2795 - val_acc: 0.3594\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0201 - acc: 0.9981 - val_loss: 4.3373 - val_acc: 0.3438\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0171 - acc: 0.9961 - val_loss: 4.3194 - val_acc: 0.3438\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 4.2991 - val_acc: 0.3438\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 4.2705 - val_acc: 0.3594\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 4.2914 - val_acc: 0.3438\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 4.3273 - val_acc: 0.3594\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 4.3337 - val_acc: 0.3281\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 4.4085 - val_acc: 0.3281\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 4.3488 - val_acc: 0.3438\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 4.3164 - val_acc: 0.3438\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 4.3382 - val_acc: 0.3438\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 4.3408 - val_acc: 0.3438\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 4.4087 - val_acc: 0.3281\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 4.4601 - val_acc: 0.3438\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 4.4528 - val_acc: 0.3281\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 4.4268 - val_acc: 0.3438\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 4.3933 - val_acc: 0.3281\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 4.3520 - val_acc: 0.3594\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 4.3406 - val_acc: 0.3594\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 4.3714 - val_acc: 0.3438\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 4.4088 - val_acc: 0.3438\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 4.4357 - val_acc: 0.3594\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 4.4620 - val_acc: 0.3438\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 4.4852 - val_acc: 0.3438\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 4.4945 - val_acc: 0.3750\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 4.4990 - val_acc: 0.3438\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 4.5044 - val_acc: 0.3594\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 4.5187 - val_acc: 0.3750\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 4.5084 - val_acc: 0.3438\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 4.4842 - val_acc: 0.3594\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 4.4963 - val_acc: 0.3594\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 4.4879 - val_acc: 0.3438\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 4.4715 - val_acc: 0.3594\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 4.4656 - val_acc: 0.3594\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 4.4833 - val_acc: 0.3750\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 4.5207 - val_acc: 0.3438\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 4.5463 - val_acc: 0.3594\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 4.5269 - val_acc: 0.3438\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 4.5079 - val_acc: 0.3438\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 4.5012 - val_acc: 0.3438\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 4.5129 - val_acc: 0.3438\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 4.5568 - val_acc: 0.3438\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 4.5567 - val_acc: 0.3438\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 4.5410 - val_acc: 0.3594\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 4.5444 - val_acc: 0.3750\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 4.5458 - val_acc: 0.3750\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 4.5420 - val_acc: 0.3594\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 4.5655 - val_acc: 0.3438\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 4.5733 - val_acc: 0.3438\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 4.5955 - val_acc: 0.3594\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 4.5955 - val_acc: 0.3594\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 4.5798 - val_acc: 0.3438\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 4.5565 - val_acc: 0.3594\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 4.5446 - val_acc: 0.3438\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 4.5488 - val_acc: 0.3438\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 4.5525 - val_acc: 0.3438\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 4.6548 - val_acc: 0.3594\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 4.6455 - val_acc: 0.3438\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 4.6172 - val_acc: 0.3438\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 4.6140 - val_acc: 0.3438\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 4.6271 - val_acc: 0.3281\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 4.6252 - val_acc: 0.3438\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 4.6386 - val_acc: 0.3438\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 4.6281 - val_acc: 0.3594\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 4.6284 - val_acc: 0.3438\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 4.6206 - val_acc: 0.3438\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 4.6358 - val_acc: 0.3594\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 4.6433 - val_acc: 0.3438\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 4.6303 - val_acc: 0.3281\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 4.6179 - val_acc: 0.3438\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 4.6407 - val_acc: 0.3594\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 4.6674 - val_acc: 0.3594\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 4.6651 - val_acc: 0.3438\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 4.6570 - val_acc: 0.3906\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 4.6633 - val_acc: 0.3594\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 4.6663 - val_acc: 0.3438\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 4.6786 - val_acc: 0.3438\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 4.6907 - val_acc: 0.3438\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 4.6898 - val_acc: 0.3438\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 4.7017 - val_acc: 0.3750\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 4.6962 - val_acc: 0.3594\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 4.7052 - val_acc: 0.3438\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 4.7064 - val_acc: 0.3594\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 4.7085 - val_acc: 0.3594\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 4.7008 - val_acc: 0.3438\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 4.7122 - val_acc: 0.3438\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 4.7548 - val_acc: 0.3906\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 4.7523 - val_acc: 0.3594\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 4.7332 - val_acc: 0.3438\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 4.7180 - val_acc: 0.3594\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 4.7182 - val_acc: 0.3594\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 4.7420 - val_acc: 0.3594\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 4.7409 - val_acc: 0.3438\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 4.7544 - val_acc: 0.3438\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 4.7662 - val_acc: 0.3438\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 4.7742 - val_acc: 0.3438\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 4.7581 - val_acc: 0.3438\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 4.7565 - val_acc: 0.3438\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 4.7625 - val_acc: 0.3438\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 4.7748 - val_acc: 0.3594\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 4.7702 - val_acc: 0.3438\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 4.7867 - val_acc: 0.3438\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 4.7975 - val_acc: 0.3438\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 4.7943 - val_acc: 0.3594\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 4.7987 - val_acc: 0.3438\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 4.8055 - val_acc: 0.3438\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 4.8149 - val_acc: 0.3438\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 4.8459 - val_acc: 0.3750\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 4.8261 - val_acc: 0.3594\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 4.8218 - val_acc: 0.3438\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 4.8308 - val_acc: 0.3594\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 4.8157 - val_acc: 0.3438\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 4.8196 - val_acc: 0.3438\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 4.8370 - val_acc: 0.3438\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 4.8516 - val_acc: 0.3438\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 4.8489 - val_acc: 0.3750\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 4.8685 - val_acc: 0.3438\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 4.9096 - val_acc: 0.3750\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 4.8880 - val_acc: 0.3750\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 4.8647 - val_acc: 0.3750\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 4.8779 - val_acc: 0.3906\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 4.9001 - val_acc: 0.3438\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 4.8924 - val_acc: 0.3594\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 4.8803 - val_acc: 0.3750\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 4.8561 - val_acc: 0.3750\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 4.8740 - val_acc: 0.3438\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 4.8971 - val_acc: 0.3594\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 4.9005 - val_acc: 0.3594\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 4.9011 - val_acc: 0.3438\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 4.8953 - val_acc: 0.3438\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 4.9016 - val_acc: 0.3438\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 4.9131 - val_acc: 0.3438\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 4.9107 - val_acc: 0.3594\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 4.9016 - val_acc: 0.3438\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 4.9226 - val_acc: 0.3438\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 4.9489 - val_acc: 0.3438\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 4.9366 - val_acc: 0.3438\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 4.9186 - val_acc: 0.3438\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 4.9088 - val_acc: 0.3438\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 4.9166 - val_acc: 0.3438\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 4.9476 - val_acc: 0.3594\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 4.9244 - val_acc: 0.3594\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0316 - acc: 0.9903 - val_loss: 5.3804 - val_acc: 0.3594\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.0926 - acc: 0.9767 - val_loss: 4.9949 - val_acc: 0.3125\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0441 - acc: 0.9864 - val_loss: 4.9940 - val_acc: 0.4062\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.1169 - acc: 0.9690 - val_loss: 5.4062 - val_acc: 0.3125\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.1645 - acc: 0.9496 - val_loss: 5.3408 - val_acc: 0.3125\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1594 - acc: 0.9380 - val_loss: 5.8590 - val_acc: 0.3750\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.2366 - acc: 0.9244 - val_loss: 5.1010 - val_acc: 0.3438\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.1470 - acc: 0.9477 - val_loss: 5.9543 - val_acc: 0.3438\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.6154 - acc: 0.8527 - val_loss: 4.9944 - val_acc: 0.3750\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.5247 - acc: 0.8605 - val_loss: 5.3352 - val_acc: 0.3906\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.4102 - acc: 0.8585 - val_loss: 4.7452 - val_acc: 0.3594\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.5218 - acc: 0.8488 - val_loss: 5.3589 - val_acc: 0.2656\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3810 - acc: 0.8760 - val_loss: 4.5262 - val_acc: 0.3750\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.2612 - acc: 0.9070 - val_loss: 4.6503 - val_acc: 0.2812\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1712 - acc: 0.9438 - val_loss: 4.4341 - val_acc: 0.3125\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.1398 - acc: 0.9457 - val_loss: 4.4117 - val_acc: 0.3438\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0940 - acc: 0.9729 - val_loss: 4.9529 - val_acc: 0.3281\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.0832 - acc: 0.9748 - val_loss: 4.5485 - val_acc: 0.3594\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0604 - acc: 0.9787 - val_loss: 4.4862 - val_acc: 0.4219\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0342 - acc: 0.9961 - val_loss: 4.5091 - val_acc: 0.3438\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0270 - acc: 0.9942 - val_loss: 4.5092 - val_acc: 0.3281\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 4.4905 - val_acc: 0.3281\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 4.4894 - val_acc: 0.3594\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "#pitch_index = all_targets.index(pitch)\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=500, \n",
    "                    batch_size=100, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a file\n",
    "models.save_model(model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "23\n",
      "30\n",
      "32\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "# See which are 'stop'\n",
    "for idx, y in enumerate(y_test):\n",
    "    if y == 1:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 188ms/step\n",
      "Answer: 3.0  Prediction: 8 Value: 0.95606095\n",
      "Predict Values [[1.6746614e-12 3.6962501e-16 7.4680753e-18 2.0604075e-03 1.2061274e-06\n",
      "  1.1858376e-05 1.9245181e-02 1.1717171e-03 9.5606095e-01 2.1342162e-02\n",
      "  1.0642443e-04 2.3638147e-34]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Answer: 11.0  Prediction: 2 Value: 0.9741789\n",
      "Predict Values [[4.5401184e-03 2.1279970e-02 9.7417891e-01 1.3614845e-11 8.8709526e-11\n",
      "  1.0269882e-13 4.3208263e-11 4.2810530e-07 1.0440488e-09 1.1055981e-19\n",
      "  5.4047744e-09 5.0066859e-07]]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Answer: 2.0  Prediction: 2 Value: 0.9998524\n",
      "Predict Values [[8.4537307e-05 1.6641590e-05 9.9985242e-01 2.3475730e-10 4.2399519e-09\n",
      "  6.9195534e-13 1.3057580e-08 1.3302019e-08 1.1203929e-07 4.5818161e-16\n",
      "  4.6192574e-05 7.9918609e-15]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Answer: 5.0  Prediction: 4 Value: 0.7420018\n",
      "Predict Values [[2.29238778e-24 1.62012875e-25 1.75573512e-20 2.17354205e-02\n",
      "  7.42001772e-01 2.08974302e-01 1.04051294e-04 1.17568998e-05\n",
      "  4.17498173e-03 2.15154421e-02 1.48228777e-03 0.00000000e+00]]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Answer: 2.0  Prediction: 1 Value: 0.7467877\n",
      "Predict Values [[2.33803779e-01 7.46787727e-01 1.94085687e-02 1.09147283e-13\n",
      "  7.83000916e-14 1.54794957e-21 1.13372114e-13 1.08466699e-11\n",
      "  6.47959294e-17 7.32648083e-16 2.32970282e-10 3.12888426e-09]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Answer: 3.0  Prediction: 10 Value: 0.5747692\n",
      "Predict Values [[2.6940489e-08 4.5596389e-03 4.0471992e-01 2.6826901e-05 1.5749073e-02\n",
      "  4.1026590e-07 1.5816429e-04 7.4459741e-08 1.6724103e-05 6.8205989e-11\n",
      "  5.7476920e-01 2.2201374e-09]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 3.0  Prediction: 3 Value: 0.8137877\n",
      "Predict Values [[7.2114759e-13 2.3245222e-11 1.0081588e-12 8.1378770e-01 1.2735670e-03\n",
      "  4.6142368e-03 1.3257375e-01 1.2734691e-04 4.7045894e-02 5.4307509e-04\n",
      "  3.4449491e-05 3.4025242e-21]]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 1.0\n",
      "Predict Values [[4.4841349e-11 7.5074344e-19 5.6349467e-13 2.8697483e-33 3.9514544e-24\n",
      "  5.3325723e-34 2.1122321e-38 3.9063950e-20 9.2566668e-33 0.0000000e+00\n",
      "  2.4434865e-28 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Answer: 9.0  Prediction: 10 Value: 0.36280367\n",
      "Predict Values [[2.1869514e-15 3.9381963e-16 2.1997838e-10 9.4100833e-02 4.5528203e-02\n",
      "  3.0292171e-01 3.4638220e-03 8.9414453e-04 7.3769670e-03 1.8291067e-01\n",
      "  3.6280367e-01 9.9124893e-24]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 0.99999905\n",
      "Predict Values [[3.5942577e-12 6.7804654e-16 9.4477298e-07 1.2729446e-21 3.5406852e-21\n",
      "  1.0489291e-24 5.5938019e-31 6.8304852e-14 2.0526086e-15 0.0000000e+00\n",
      "  9.6062271e-16 9.9999905e-01]]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Answer: 10.0  Prediction: 6 Value: 0.5906139\n",
      "Predict Values [[1.5622815e-04 5.8275756e-08 4.1759074e-16 2.5769144e-01 5.3292238e-06\n",
      "  7.7992110e-05 5.9061390e-01 2.7327242e-04 1.1366280e-01 1.3913220e-05\n",
      "  3.7505042e-02 2.1566206e-23]]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Answer: 4.0  Prediction: 4 Value: 0.9887317\n",
      "Predict Values [[1.1240636e-26 9.0212729e-24 1.0940934e-28 4.2581151e-12 9.8873168e-01\n",
      "  5.2490112e-05 6.3696127e-08 1.8233281e-11 6.3457333e-07 1.1211974e-02\n",
      "  3.2449107e-06 7.7786485e-35]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 1.0\n",
      "Predict Values [[3.2593801e-16 2.0351433e-10 5.1814951e-08 1.4345538e-25 9.9030559e-29\n",
      "  9.8519517e-31 4.3867421e-25 1.4083154e-18 4.8743026e-22 2.0958906e-38\n",
      "  1.7387637e-20 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Answer: 6.0  Prediction: 8 Value: 0.8937745\n",
      "Predict Values [[6.7032610e-16 4.1469536e-11 1.4164017e-17 4.8523568e-12 3.5852587e-04\n",
      "  2.6891732e-08 4.9927735e-07 7.6417752e-02 8.9377451e-01 2.1058019e-08\n",
      "  2.9448703e-02 8.6732410e-16]]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Answer: 6.0  Prediction: 3 Value: 0.8951019\n",
      "Predict Values [[1.3555652e-13 1.6890171e-14 2.0384779e-11 8.9510190e-01 3.0672182e-03\n",
      "  3.9924183e-03 6.3794156e-05 1.6786193e-05 9.7653270e-02 1.0376087e-04\n",
      "  8.7565763e-07 2.0498306e-23]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Answer: 5.0  Prediction: 8 Value: 0.5857052\n",
      "Predict Values [[5.0308100e-09 2.1602605e-07 1.3955787e-06 2.5318995e-01 1.5696700e-01\n",
      "  1.1874944e-03 2.5031616e-03 4.1354564e-04 5.8570522e-01 7.9016072e-06\n",
      "  2.4185281e-05 9.8637611e-16]]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Answer: 9.0  Prediction: 4 Value: 0.98853683\n",
      "Predict Values [[5.4305250e-27 1.5597858e-22 6.0954967e-24 8.4680330e-14 9.8853683e-01\n",
      "  2.7115518e-11 4.1182218e-03 7.7295514e-10 1.0449893e-08 7.3446124e-03\n",
      "  2.5633562e-07 3.0805588e-34]]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Answer: 8.0  Prediction: 8 Value: 0.8036\n",
      "Predict Values [[3.3768078e-16 3.6667332e-17 4.9950597e-07 8.8647736e-05 7.2719360e-04\n",
      "  5.9979176e-03 3.0787513e-04 1.8318784e-01 8.0360001e-01 5.7640825e-03\n",
      "  3.2593211e-04 2.7650166e-27]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 0.9998914\n",
      "Predict Values [[6.66572324e-15 1.42622984e-14 1.35911492e-07 1.08365848e-16\n",
      "  1.39789328e-16 1.22014285e-17 2.23657323e-23 2.89097510e-08\n",
      "  1.08474465e-04 1.23547096e-27 6.93151281e-17 9.99891400e-01]]\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Answer: 3.0  Prediction: 7 Value: 0.45880067\n",
      "Predict Values [[2.5045230e-10 7.9181199e-15 1.5296710e-13 5.3247293e-03 3.0357612e-04\n",
      "  1.1413486e-02 9.7284667e-02 4.5880067e-01 2.6511954e-02 4.0032956e-01\n",
      "  3.1300140e-05 5.7132989e-27]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Answer: 5.0  Prediction: 4 Value: 0.99988675\n",
      "Predict Values [[1.04483264e-19 3.99673235e-21 4.96126900e-25 1.47992830e-06\n",
      "  9.99886751e-01 5.81713357e-05 6.31582253e-09 1.86408267e-12\n",
      "  1.80170030e-08 2.43078139e-05 2.92876484e-05 1.49124235e-38]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Answer: 6.0  Prediction: 9 Value: 0.6992116\n",
      "Predict Values [[2.6399839e-16 5.9331582e-16 8.2900572e-22 6.1632099e-04 4.6381191e-03\n",
      "  2.1752485e-04 2.9503056e-01 2.2818367e-05 2.6305151e-04 6.9921160e-01\n",
      "  2.1723074e-09 3.8008019e-34]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Answer: 1.0  Prediction: 0 Value: 0.99964845\n",
      "Predict Values [[9.9964845e-01 2.7738814e-04 7.2504918e-05 1.6680925e-06 1.1048436e-08\n",
      "  1.1216216e-16 3.5473149e-11 1.0652921e-11 3.5448714e-12 8.5762722e-19\n",
      "  1.6254063e-10 1.6755937e-12]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Answer: 7.0  Prediction: 8 Value: 0.9999368\n",
      "Predict Values [[3.9341951e-16 3.5735057e-09 5.5652504e-13 3.2537719e-06 9.9810924e-09\n",
      "  4.9422107e-07 1.3049178e-07 5.9303362e-05 9.9993682e-01 7.7957606e-13\n",
      "  2.7637585e-08 2.1085539e-18]]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 1.0\n",
      "Predict Values [[5.5592276e-20 5.8510516e-21 4.1818437e-14 1.9079263e-34 6.8102566e-31\n",
      "  0.0000000e+00 3.8986180e-38 1.5038829e-23 0.0000000e+00 0.0000000e+00\n",
      "  3.0586095e-33 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Answer: 7.0  Prediction: 9 Value: 0.98370624\n",
      "Predict Values [[9.4266360e-16 2.0390155e-19 4.2339705e-11 3.8029524e-03 5.4458402e-09\n",
      "  3.2120801e-03 3.2707831e-05 6.9903749e-06 2.8724630e-08 9.8370624e-01\n",
      "  9.2390859e-03 5.8353235e-22]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Answer: 6.0  Prediction: 8 Value: 0.9972868\n",
      "Predict Values [[1.1343535e-16 2.4197220e-19 3.4303136e-19 1.1512134e-08 4.0029455e-08\n",
      "  4.1970099e-09 2.7119885e-03 1.4384756e-07 9.9728680e-01 1.0729181e-06\n",
      "  4.6757168e-11 3.2476229e-32]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 0.99999046\n",
      "Predict Values [[4.2859660e-06 2.4767175e-09 5.2210044e-06 7.1163640e-22 1.8245391e-16\n",
      "  4.3281366e-27 4.2043937e-27 9.5469551e-14 7.6705371e-21 9.0334234e-34\n",
      "  1.7898227e-16 9.9999046e-01]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Answer: 4.0  Prediction: 5 Value: 0.99984014\n",
      "Predict Values [[9.4251689e-19 3.1537371e-27 6.7130702e-16 5.0875713e-08 2.8549699e-11\n",
      "  9.9984014e-01 8.1108158e-07 5.9014787e-06 1.2616977e-08 2.0746040e-07\n",
      "  1.5282161e-04 1.2205638e-33]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Answer: 1.0  Prediction: 1 Value: 0.969777\n",
      "Predict Values [[1.3818332e-02 9.6977699e-01 1.6404700e-02 5.4785424e-13 4.8390094e-11\n",
      "  1.7116375e-12 4.8981423e-11 1.1375703e-08 5.5997513e-13 2.8178127e-23\n",
      "  1.2090574e-10 9.7988566e-13]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Answer: 6.0  Prediction: 10 Value: 0.999998\n",
      "Predict Values [[1.3073768e-22 9.5392058e-24 1.8803627e-21 3.7435204e-11 3.2271872e-09\n",
      "  1.8222054e-12 2.6713946e-12 2.0289187e-06 9.0100318e-09 3.3663693e-11\n",
      "  9.9999797e-01 1.9412437e-21]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Answer: 1.0  Prediction: 1 Value: 0.67854327\n",
      "Predict Values [[2.2466140e-02 6.7854327e-01 2.9899058e-01 5.4697823e-11 7.6401056e-12\n",
      "  1.6712257e-13 2.4882857e-10 9.3715862e-09 1.6286988e-13 2.0249956e-18\n",
      "  1.7008206e-09 9.0392546e-12]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 1.0\n",
      "Predict Values [[2.0571447e-08 2.8754885e-12 3.3369154e-09 2.9289956e-26 1.1225917e-20\n",
      "  5.0129721e-32 2.0921217e-29 1.2218458e-16 2.1007337e-30 0.0000000e+00\n",
      "  3.2784913e-27 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Answer: 9.0  Prediction: 6 Value: 0.63292545\n",
      "Predict Values [[1.7183397e-13 6.7684234e-15 7.5016431e-11 6.6898968e-03 7.0239385e-06\n",
      "  2.2099821e-03 6.3292545e-01 3.5121766e-01 4.3940479e-03 1.8158942e-04\n",
      "  2.3743748e-03 1.3999717e-28]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Answer: 7.0  Prediction: 5 Value: 0.998027\n",
      "Predict Values [[1.3097752e-17 3.0788466e-22 4.9547202e-12 1.7125768e-03 1.2061646e-06\n",
      "  9.9802703e-01 3.3432552e-05 9.8027958e-05 2.9091640e-09 1.2775627e-04\n",
      "  3.1391729e-09 1.7572987e-25]]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Answer: 10.0  Prediction: 6 Value: 0.8557146\n",
      "Predict Values [[1.1428096e-12 2.0689541e-16 4.9020031e-19 4.7755498e-03 7.2223534e-06\n",
      "  1.2817389e-01 8.5571462e-01 2.0310830e-03 2.9283192e-04 5.7236515e-03\n",
      "  3.2812420e-03 7.8174415e-33]]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Answer: 9.0  Prediction: 9 Value: 0.79367083\n",
      "Predict Values [[2.9648457e-18 1.0582482e-21 1.3991652e-13 5.7862977e-09 3.2376252e-06\n",
      "  9.5595465e-07 2.8763261e-06 5.1004940e-04 3.7001693e-11 7.9367083e-01\n",
      "  2.0581199e-01 1.8460097e-29]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Answer: 2.0  Prediction: 1 Value: 0.9843352\n",
      "Predict Values [[2.9725805e-05 9.8433518e-01 1.4862975e-02 6.3284426e-07 8.2995825e-08\n",
      "  3.2331807e-14 2.8530371e-11 2.3899515e-06 4.1189028e-11 5.8837910e-16\n",
      "  5.9836646e-13 7.6898217e-04]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Answer: 1.0  Prediction: 1 Value: 0.6542484\n",
      "Predict Values [[3.3228087e-01 6.5424842e-01 1.3335521e-02 1.5549706e-07 1.3287746e-10\n",
      "  1.9016844e-09 9.2502725e-09 6.3015655e-11 8.8996545e-12 5.2629051e-19\n",
      "  1.3502718e-04 6.3920586e-13]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Answer: 5.0  Prediction: 10 Value: 0.75343114\n",
      "Predict Values [[1.7622262e-18 8.3440015e-20 6.7301720e-11 4.0586246e-03 3.6563972e-07\n",
      "  2.3344637e-01 1.5660922e-07 8.5544083e-03 4.6300999e-04 4.5932400e-05\n",
      "  7.5343114e-01 2.2141847e-17]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 8.0  Prediction: 5 Value: 0.9982028\n",
      "Predict Values [[4.8813814e-22 4.6919139e-27 2.1352821e-10 3.0279878e-08 6.4267835e-10\n",
      "  9.9820280e-01 1.7580351e-05 2.6018151e-05 1.1054533e-08 1.7535025e-03\n",
      "  4.8144300e-10 1.6835455e-31]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: 10.0  Prediction: 7 Value: 0.581479\n",
      "Predict Values [[1.16672724e-14 5.13456920e-16 4.42059682e-04 4.25228057e-03\n",
      "  1.16588495e-07 4.12837952e-01 1.71080246e-05 5.81479013e-01\n",
      "  2.46813511e-06 5.97322605e-06 9.63000755e-04 1.27143227e-25]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Answer: 8.0  Prediction: 9 Value: 0.9992544\n",
      "Predict Values [[4.9928443e-33 1.3804360e-33 5.3537379e-12 6.6690011e-23 1.6520932e-14\n",
      "  3.8452002e-09 1.8353565e-11 1.1305915e-09 3.3898993e-15 9.9925441e-01\n",
      "  7.4558199e-04 2.2795591e-34]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 1.0\n",
      "Predict Values [[1.5505078e-13 8.0411457e-23 1.5153584e-10 3.0904573e-37 7.4891891e-33\n",
      "  0.0000000e+00 0.0000000e+00 5.9618558e-29 0.0000000e+00 0.0000000e+00\n",
      "  2.6281699e-26 1.0000000e+00]]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Answer: 5.0  Prediction: 3 Value: 0.9730996\n",
      "Predict Values [[9.7866804e-10 7.2387400e-07 1.4892214e-03 9.7309959e-01 3.8015691e-03\n",
      "  1.3442034e-06 1.2282610e-02 9.2340037e-03 9.0093250e-05 5.4026718e-12\n",
      "  8.2374197e-07 9.7789850e-19]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Answer: 4.0  Prediction: 6 Value: 0.43380105\n",
      "Predict Values [[7.7864509e-22 7.1313270e-24 3.8626892e-19 2.7529812e-01 6.7767906e-03\n",
      "  3.6267251e-02 4.3380105e-01 9.5257349e-03 2.3617439e-01 2.1545326e-03\n",
      "  2.0613131e-06 0.0000000e+00]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Answer: 8.0  Prediction: 8 Value: 0.9999994\n",
      "Predict Values [[5.0655478e-12 1.0422612e-15 1.4872553e-18 4.4558159e-12 3.5168781e-11\n",
      "  1.2735047e-08 1.9664847e-12 1.5598934e-08 9.9999940e-01 1.3310954e-12\n",
      "  6.0156111e-07 1.2681094e-19]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Answer: 10.0  Prediction: 8 Value: 0.99999917\n",
      "Predict Values [[4.2552126e-10 4.1724519e-08 1.6914082e-15 4.2103467e-15 8.1272500e-13\n",
      "  1.7355650e-16 2.0416650e-18 2.7332895e-11 9.9999917e-01 5.5878759e-15\n",
      "  7.7608564e-07 8.3340461e-15]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Answer: 10.0  Prediction: 10 Value: 0.99864346\n",
      "Predict Values [[8.0601636e-11 5.7471380e-18 9.2066798e-15 3.0960605e-09 1.1041777e-07\n",
      "  7.8155954e-10 1.9274270e-07 1.9978159e-09 1.3561436e-03 5.9456582e-09\n",
      "  9.9864346e-01 6.7369534e-24]]\n",
      "\n",
      "Test Score:  18 / 50  =  0.36\n"
     ]
    }
   ],
   "source": [
    "# TEST: Load model and run it against test set\n",
    "model = models.load_model(model_filename)\n",
    "correct = 0\n",
    "testRange = 50\n",
    "for i in range(1, testRange):\n",
    "    maxV = -1\n",
    "    predict = -1\n",
    "    counter = 0\n",
    "    pre = model.predict(np.expand_dims(x_test[i], 0))\n",
    "    for j in range(12):\n",
    "        #print(pre[0][j])\n",
    "        if(pre[0][j] > maxV):\n",
    "            maxV = pre[0][j]\n",
    "            predict = counter\n",
    "        counter = counter + 1\n",
    "            \n",
    "    print('Answer:', y_test[i], ' Prediction:', predict, 'Value:', maxV)\n",
    "    print(\"Predict Values\", pre)\n",
    "    if y_test[i] == predict:\n",
    "        correct = correct+1\n",
    "print()\n",
    "print(\"Test Score: \", correct, \"/\",testRange,\" = \", correct/testRange) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 15ms/step - loss: 6.2303 - acc: 0.3438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.230274677276611, 0.34375]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model with test set\n",
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
