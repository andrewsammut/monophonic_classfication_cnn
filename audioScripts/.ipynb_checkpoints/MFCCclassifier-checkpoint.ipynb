{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "from tensorflow.keras import layers, models, utils\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A#3', 'A#4', 'A3', 'A4', 'B3', 'B4', 'C#3', 'C#4', 'C3', 'C4', 'D#3', 'D#4', 'D3', 'D4', 'E3', 'E4', 'F#3', 'F#4', 'F3', 'F4', 'G3', 'G4']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Create list of all targets (minus background noise)\n",
    "\n",
    "dataset_path = 'C:\\\\Users\\\\Greg\\\\ML\\\\Technical\\\\project\\\\git2\\\\monophonic_classfication_cnn\\\\padded'\n",
    "all_targets = all_targets = [name for name in listdir(dataset_path) if isdir(join(dataset_path, name))]\n",
    "all_targets.remove('_background_noise_')\n",
    "train_target = ['A3', 'A#3', 'B3', 'C3', 'C#3','D3', 'D#3', 'E3', 'F3', 'F#3','G3','A4']\n",
    "print(all_targets)\n",
    "numclasses = len(train_target)\n",
    "print(numclasses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "feature_sets_path = 'C:\\\\Users\\\\Greg\\\\ML\\\\Technical\\\\project\\\\git2\\\\monophonic_classfication_cnn\\\\audioScripts'\n",
    "feature_sets_filename = 'all_targets_mfcc_sets.npz'\n",
    "model_filename = 'AudioModel.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_train', 'y_train', 'x_val', 'y_val', 'x_test', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "# Load feature sets\n",
    "feature_sets = np.load(join(feature_sets_path, feature_sets_filename))\n",
    "print(feature_sets.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign feature sets\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 16, 16)\n",
      "(64, 16, 16)\n",
      "(64, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "# Look at tensor dimensions\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.  8.  5.  2. 11.  0.  5.  8.  0.  9.  2.  0.  0. 11.  0.  7.  9.  9.\n",
      " 11.  0.  2.  1.  3.  7.  2.  9.  2.  0. 11.  7. 11.  2. 10.  2.  4. 10.\n",
      "  3.  7.  8.  7.  9.  3.  7. 10. 10.  0. 11.  9.  1.  1.  2.  7.  1.  6.\n",
      "  3.  1.  7.  8.  4.  8.  8.  3. 11. 10.]\n"
     ]
    }
   ],
   "source": [
    "# Peek at labels\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ground truth arrays to one wake word (1) and 'other' (0)\n",
    "#ytr = []\n",
    "#yv = []\n",
    "#yts = []\n",
    "#count = 1\n",
    "#for pitch in all_targets:\n",
    "#    pitch_index = all_targets.index(pitch)\n",
    "#    ytr.append(np.equal(y_train, pitch_index).astype('float64'))\n",
    "#    yv.append( np.equal(y_val, pitch_index).astype('float64'))\n",
    "#    yts.append(np.equal(y_test, pitch_index).astype('float64'))\n",
    "    #count = count + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  3.  6.  7.  6.  8.  6.  9. 11.  8.  8.  9.  0.  9. 10.  5.  8.  8.\n",
      "  5. 10. 10.  7.  2.  1.  7. 10.  2.  7.  1.  0. 10.  9. 11.  2.  5.  8.\n",
      "  8.  2.  4. 10.  3.  3.  5. 11.  8.  5.  1.  7.  0.  9.  8.  7.  0.  2.\n",
      "  2.  2.  7.  4.  9.  0.  0.  0.  1.  4.  0.  1.  6.  6.  2. 10.  4. 11.\n",
      "  5.  1.  6.  4.  5.  7.  2.  4.  0.  8. 11. 11.  6.  1. 10.  2.  7.  6.\n",
      " 11.  6.  1. 10.  7. 11.  1.  4.  1.  3.  4.  4.  5.  6.  0.  6.  0.  3.\n",
      "  5.  1. 10.  1.  2. 10. 11.  0. 10.  8.  3. 11.  7.  9.  0.  9.  0.  5.\n",
      " 10.  6.  1.  8.  5.  2.  1. 10.  4.  2.  1. 11.  8.  1.  9.  7.  9.  1.\n",
      "  6.  5.  9.  2.  0.  0.  7.  9.  2.  1. 11.  5.  7. 11. 11.  1.  1.  1.\n",
      "  6.  0.  8. 11.  9. 10.  2.  0.  3.  5.  3. 10.  0.  6.  2.  8.  9.  8.\n",
      "  5.  8.  7. 10.  7. 10. 11.  7.  1.  0.  1.  0.  6.  5.  2.  9.  2. 11.\n",
      " 11.  8. 10.  9.  9.  7.  2.  6.  5.  2.  7.  7.  8. 10.  7.  6.  5.  0.\n",
      "  8.  9.  2.  6.  4.  8. 11. 10.  1. 11.  4. 10. 10.  5.  0.  4.  1.  4.\n",
      "  4.  2.  4.  5. 11.  6.  4. 10. 10.  4.  6.  0.  1. 11.  4.  5.  1.  7.\n",
      "  8.  1.  5.  1.  6.  6.  9.  6. 10.  0. 11. 11.  0.  6.  1.  4.  6. 10.\n",
      "  1.  0.  5.  1. 10.  1.  9.  1.  8.  6.  0. 11.  6.  5.  9.  6. 11.  0.\n",
      " 10.  5.  8.  2.  0.  6.  8.  6.  9.  8.  1.  2.  6.  4.  9. 10.  9. 11.\n",
      "  3.  7.  9. 10. 11.  2. 10.  8.  2.  9. 11.  3. 11. 10.  0.  6.  3.  6.\n",
      "  5.  5. 10.  3. 11.  8. 10.  9.  7.  5.  2.  0.  3.  2.  0.  9.  5.  2.\n",
      "  4.  9.  9.  3.  6.  9. 11.  5.  6.  1.  4.  1. 11.  1.  0.  2.  0.  2.\n",
      " 11. 10.  7.  5.  9.  6.  2.  0.  3.  4.  6. 10.  9.  1.  1.  9.  2.  5.\n",
      "  2.  4.  2. 11. 10.  2.  8.  0. 11. 11.  4.  3.  6.  1. 10.  7.  6.  3.\n",
      "  2. 11.  9.  7.  9. 11.  0.  0.  7.  0. 11.  9.  3. 10.  1. 11.  8.  1.\n",
      "  5.  7.  4.  1.  7.  7.  4. 11.  3.  9.  0. 11.  5.  1.  5.  1.  3. 11.\n",
      "  0. 10.  9. 10. 10.  3. 11.  3.  0.  1.  7.  4. 10. 11.  0.  4.  1.  7.\n",
      "  1.  3. 10.  5.  6. 10.  9.  3.  2. 11.  5.  2.  2.  5.  1.  4. 11.  5.\n",
      "  0.  2.  9.  2.  5.  8.  7.  2.  5.  6.  2.  5.  2.  8.  4.  8.  5.  4.\n",
      " 10.  8.  5. 11. 11.  6.  2. 11. 10.  6.  3. 11.  7.  4.  1.  4.  2. 11.\n",
      "  1.  6.  3.  5.  8. 10.  8.  5.  7.  7.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "# Peek at labels after conversion\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What percentage of 'stop' appear in validation labels\n",
    "#print(sum(y_val) / len(y_val))\n",
    "#print(1 - sum(y_val) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dimensions of our input data\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 16, 16, 1)\n",
      "(64, 16, 16, 1)\n",
      "(64, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN for TF expects (batch, height, width, channels)\n",
    "# So we reshape the input tensors with a \"color\" channel of 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], x_val.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "#y_train = utils.to_categorical(y_train, numclasses)\n",
    "#y_test = utils.to_categorical(y_test, numclasses)\n",
    "#y_val = utils.to_categorical(y_val, numclasses)\n",
    "\n",
    "#fig=plt.figure()\n",
    "#plt.imshow(x_val[11], cmap='inferno', origin='lower')\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Input shape for CNN is size of MFCC of 1 sample\n",
    "sample_shape = x_test.shape[1:]\n",
    "print(sample_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "# Based on: https://www.geeksforgeeks.org/python-image-classification-using-keras/\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, 2, activation='relu',input_shape=sample_shape))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Classifier\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(numclasses, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 15, 15, 32)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 7, 7, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 32)          4128      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                18496     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,564\n",
      "Trainable params: 23,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training parameters to model\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 1s 65ms/step - loss: 3.7088 - acc: 0.0872 - val_loss: 2.4280 - val_acc: 0.2031\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9950 - acc: 0.3566 - val_loss: 1.7229 - val_acc: 0.4062\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.3203 - acc: 0.6512 - val_loss: 1.1357 - val_acc: 0.8281\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8062 - acc: 0.9167 - val_loss: 0.7648 - val_acc: 0.9062\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4705 - acc: 0.9632 - val_loss: 0.4948 - val_acc: 0.9219\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2667 - acc: 0.9767 - val_loss: 0.3195 - val_acc: 0.9219\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1650 - acc: 0.9826 - val_loss: 0.2716 - val_acc: 0.9219\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1066 - acc: 0.9864 - val_loss: 0.2538 - val_acc: 0.9219\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0817 - acc: 0.9903 - val_loss: 0.1895 - val_acc: 0.9688\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0646 - acc: 0.9903 - val_loss: 0.1625 - val_acc: 0.9688\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0541 - acc: 0.9922 - val_loss: 0.1504 - val_acc: 0.9531\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0457 - acc: 0.9903 - val_loss: 0.1363 - val_acc: 0.9688\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0404 - acc: 0.9903 - val_loss: 0.1265 - val_acc: 0.9531\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0373 - acc: 0.9942 - val_loss: 0.1195 - val_acc: 0.9688\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0342 - acc: 0.9942 - val_loss: 0.1082 - val_acc: 0.9688\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0317 - acc: 0.9903 - val_loss: 0.1136 - val_acc: 0.9688\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0302 - acc: 0.9942 - val_loss: 0.1026 - val_acc: 0.9688\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0274 - acc: 0.9942 - val_loss: 0.0959 - val_acc: 0.9688\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0285 - acc: 0.9922 - val_loss: 0.1127 - val_acc: 0.9531\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0265 - acc: 0.9903 - val_loss: 0.0894 - val_acc: 0.9688\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0236 - acc: 0.9981 - val_loss: 0.0845 - val_acc: 0.9688\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 0.9688\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0182 - acc: 0.9961 - val_loss: 0.0803 - val_acc: 0.9688\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0182 - acc: 0.9981 - val_loss: 0.0810 - val_acc: 0.9688\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0165 - acc: 0.9981 - val_loss: 0.0772 - val_acc: 0.9688\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0153 - acc: 0.9961 - val_loss: 0.0737 - val_acc: 0.9688\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0142 - acc: 0.9981 - val_loss: 0.0677 - val_acc: 0.9688\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 0.9688\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 0.9688\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9844\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9844\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 0.9844\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 0.9688\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0560 - val_acc: 0.9688\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0584 - val_acc: 0.9844\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0571 - val_acc: 0.9688\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0544 - val_acc: 0.9844\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0541 - val_acc: 0.9844\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 0.9844\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9844\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0509 - val_acc: 0.9844\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0503 - val_acc: 0.9844\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 0.9844\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0485 - val_acc: 0.9844\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 0.9844\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0462 - val_acc: 1.0000\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 1.0000\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 0.9844\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9844\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 1.0000\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 1.0000\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 0.9844\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9844\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9844\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 0.9844\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 1.0000\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 1.0000\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0377 - val_acc: 1.0000\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 0.9844\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9844\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 1.0000\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 0.9844\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 0.9844\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 0.9844\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0323 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 0.9844\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0329 - val_acc: 1.0000\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 1.0000\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0312 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 1.0000\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 1.0000\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 1.0000\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0312 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 1.0000\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0258 - val_acc: 1.0000\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 9.9825e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 9.5388e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.9355e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.7990e-04 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 9.1592e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 8.9110e-04 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.8397e-04 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.5065e-04 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.2341e-04 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.0864e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.9307e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.7807e-04 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.6757e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.4564e-04 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.4960e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.3403e-04 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.9982e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.9513e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.7873e-04 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.6292e-04 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.4998e-04 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.3908e-04 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.3231e-04 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.2169e-04 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.0969e-04 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.0188e-04 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.9552e-04 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.8451e-04 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.7834e-04 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.6374e-04 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.6454e-04 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.5855e-04 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.3588e-04 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.2080e-04 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 5.0968e-04 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.0456e-04 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.0361e-04 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.8854e-04 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.7561e-04 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.6614e-04 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.5905e-04 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.4900e-04 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.4538e-04 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.4300e-04 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.2820e-04 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3776e-04 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3496e-04 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.2262e-04 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.1007e-04 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.0261e-04 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.0231e-04 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.9069e-04 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.8059e-04 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.7494e-04 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.7404e-04 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.6788e-04 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.5969e-04 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.5176e-04 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.4719e-04 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.4118e-04 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.3856e-04 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.3373e-04 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.3036e-04 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.2430e-04 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.2000e-04 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1508e-04 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1124e-04 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0594e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.0801e-04 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.0624e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9498e-04 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.9065e-04 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.8767e-04 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.8337e-04 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.8000e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.7691e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.7399e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.7051e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.6810e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.6628e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.5916e-04 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.5842e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.5609e-04 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.5228e-04 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.4859e-04 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.4863e-04 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.4694e-04 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.4215e-04 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3814e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.3269e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3008e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.2789e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.2527e-04 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.2459e-04 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.2264e-04 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1793e-04 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.1548e-04 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.1297e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.1147e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.0905e-04 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.0747e-04 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.0486e-04 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.0156e-04 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.9991e-04 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.9738e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.9514e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.9290e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.9201e-04 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.9008e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.8703e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.8479e-04 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.8236e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.8066e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.7984e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7951e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.7504e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.7524e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.7301e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.7137e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.6806e-04 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.6639e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.6532e-04 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.6364e-04 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.6200e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.5957e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.5793e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.5631e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.5477e-04 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.5315e-04 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.5141e-04 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.5009e-04 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.4855e-04 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.4741e-04 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.4608e-04 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.4493e-04 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.4648e-04 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.4524e-04 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.4240e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.4046e-04 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.3772e-04 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.3614e-04 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.3461e-04 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.3307e-04 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.3246e-04 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.3359e-04 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.3138e-04 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.2863e-04 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.2687e-04 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.2644e-04 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.2702e-04 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.2251e-04 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.2361e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.2377e-04 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.2160e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1978e-04 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.1789e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.1730e-04 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.1598e-04 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.1467e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1271e-04 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.1445e-04 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1274e-04 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.1095e-04 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.1001e-04 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.0851e-04 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.0758e-04 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.0667e-04 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.0591e-04 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.0500e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.0350e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.0309e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0229e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.0108e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.0089e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.9323e-05 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.9644e-05 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.8527e-05 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.7572e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.6568e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.7218e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.6020e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.4633e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.3542e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 9.2596e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 9.1813e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.1064e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.0118e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.9811e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.8150e-05 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.8384e-05 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.7930e-05 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.7119e-05 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.6898e-05 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 8.5956e-05 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.5001e-05 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.4110e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.3586e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.2945e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.2390e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.1421e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.0939e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 8.0634e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 8.0111e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.9349e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.8545e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.8052e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.7370e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.6822e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.6623e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.5625e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.5364e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.4789e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.4758e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.3874e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.3110e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 7.2381e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.1929e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.1613e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.1089e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.0176e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 7.0518e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 7.0399e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.9538e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.8621e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.7791e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.7443e-05 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.7020e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.6944e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 6.6208e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.5723e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.5314e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.4818e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.4579e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.4007e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.3676e-05 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6.3228e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.2567e-05 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.2129e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.1615e-05 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 6.1331e-05 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 6.0988e-05 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.0443e-05 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 6.0216e-05 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.9623e-05 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.9088e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.8672e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.8345e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.8106e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.7515e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.7550e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.7457e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.6623e-05 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.6264e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.6045e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.5627e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.5446e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.5675e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.5061e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 5.4103e-05 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.3382e-05 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 5.2758e-05 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.2438e-05 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 5.2225e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.2643e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.1843e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.1626e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.1335e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.0706e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 5.0047e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.9594e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.9321e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.9015e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.8686e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.8313e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.8254e-05 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.8023e-05 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.7447e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.7063e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.6749e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.6586e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.6264e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.5953e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.5725e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.5391e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.5116e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.5232e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.4793e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.4459e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.4121e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3837e-05 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3838e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3833e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.3624e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3189e-05 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.2709e-05 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.2440e-05 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.1940e-05 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.1731e-05 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.1372e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.1110e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.0917e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.0803e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.0601e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.0392e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.0393e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.0340e-05 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.0066e-05 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.9678e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.8988e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.8727e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.8572e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.8246e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.8050e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.7691e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.7679e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.7611e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.7341e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6948e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.6610e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.6415e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.6335e-05 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.6026e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.5834e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.5599e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.5477e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.5238e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.5041e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.4684e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.4787e-05 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.4828e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.4635e-05 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.4419e-05 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.4262e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.3978e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.3812e-05 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.3452e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.3187e-05 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.2896e-05 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.2645e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3.2419e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.2264e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.2004e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1980e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.1751e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.1532e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.1315e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.1089e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 3.0819e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.0713e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.0530e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3.0328e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.0118e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9971e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.9884e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.9645e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.9450e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.9292e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.9150e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.9020e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.8932e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.8736e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.8565e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.8400e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.8263e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.8088e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.7918e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7657e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.7572e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.7425e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.7270e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.7073e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.6973e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.6798e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.6704e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.6547e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.6388e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.6228e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.6100e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.5916e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.5783e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.5619e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.5506e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.5447e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.5301e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.5126e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.4990e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.4859e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.4777e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.4610e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.4473e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.4316e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.4272e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.4094e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.3963e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3836e-05 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3765e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3621e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.3478e-05 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.3387e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.3270e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.3188e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3043e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.2887e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.2743e-05 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 2.2643e-05 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "#pitch_index = all_targets.index(pitch)\n",
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    epochs=500, \n",
    "                    batch_size=100, \n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a file\n",
    "models.save_model(model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "15\n",
      "27\n",
      "48\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# See which are 'stop'\n",
    "for idx, y in enumerate(y_test):\n",
    "    if y == 1:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 128ms/step\n",
      "Answer: 2.0  Prediction: 2 Value: 0.998806\n",
      "Predict Values [[1.3654934e-10 4.0500233e-08 9.9880600e-01 8.7687567e-06 4.8957998e-05\n",
      "  7.3133629e-06 9.9628994e-10 6.6302727e-07 2.3192906e-07 1.3818121e-06\n",
      "  1.9533450e-08 1.1266429e-03]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Answer: 4.0  Prediction: 4 Value: 1.0\n",
      "Predict Values [[2.1386011e-13 1.7691216e-17 1.4411212e-11 8.3277502e-10 1.0000000e+00\n",
      "  8.6897142e-11 2.8132988e-10 2.4597124e-13 2.6996980e-10 2.1081590e-08\n",
      "  2.3517709e-20 2.1494226e-12]]\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Answer: 0.0  Prediction: 0 Value: 0.9999733\n",
      "Predict Values [[9.99973297e-01 2.66482439e-05 3.75720288e-12 1.80453525e-12\n",
      "  5.29835655e-11 5.39577760e-09 7.59970700e-13 4.32165284e-12\n",
      "  1.15936575e-11 7.78062281e-10 1.54845703e-09 3.69224623e-10]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Answer: 7.0  Prediction: 7 Value: 0.999908\n",
      "Predict Values [[1.6503449e-10 5.7858740e-09 6.1763879e-11 1.0607805e-08 3.5751527e-10\n",
      "  1.4894512e-07 2.7782118e-05 9.9990797e-01 2.4327335e-06 4.8947037e-05\n",
      "  4.3187628e-10 1.2790584e-05]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 0.99999964\n",
      "Predict Values [[5.9028271e-09 7.6634308e-09 3.6953266e-12 6.6504191e-11 1.1591558e-10\n",
      "  2.0242912e-10 5.3567113e-11 6.2679395e-10 1.1334974e-09 2.3045731e-08\n",
      "  3.7472307e-07 9.9999964e-01]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Answer: 7.0  Prediction: 7 Value: 1.0\n",
      "Predict Values [[1.9574776e-13 2.8605287e-11 1.2050612e-09 1.6718952e-08 1.0656221e-11\n",
      "  1.0945223e-09 1.5806256e-08 1.0000000e+00 2.8055731e-09 2.0429566e-10\n",
      "  1.0185790e-10 5.2690252e-09]]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 0.99998176\n",
      "Predict Values [[1.9672739e-06 1.2500814e-07 2.3446634e-10 2.6240087e-08 2.4333467e-08\n",
      "  2.2717481e-08 1.4282382e-07 2.1494866e-06 3.1548089e-07 2.7355411e-06\n",
      "  1.0790022e-05 9.9998176e-01]]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Answer: 10.0  Prediction: 10 Value: 1.0\n",
      "Predict Values [[2.5222803e-11 1.1034462e-15 3.2077744e-14 4.0808742e-11 4.8070157e-14\n",
      "  4.7921647e-15 1.8125385e-19 6.7980712e-12 6.3174466e-15 8.1163739e-15\n",
      "  1.0000000e+00 7.3494627e-11]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Answer: 1.0  Prediction: 1 Value: 0.9598736\n",
      "Predict Values [[4.0864987e-05 9.5987362e-01 9.4425064e-07 4.8327462e-09 1.8578507e-07\n",
      "  2.1019880e-06 7.9237007e-06 2.3842518e-05 4.9494192e-05 1.5528833e-05\n",
      "  1.7117038e-05 3.9968465e-02]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: 8.0  Prediction: 8 Value: 1.0\n",
      "Predict Values [[3.6368304e-12 1.2660729e-15 7.1511920e-12 1.4511025e-12 3.5044739e-10\n",
      "  6.7046705e-13 2.2467093e-09 8.1377466e-12 1.0000000e+00 5.6786233e-09\n",
      "  2.9230803e-18 1.1488152e-11]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Answer: 4.0  Prediction: 4 Value: 0.99962354\n",
      "Predict Values [[7.8647318e-08 7.4163592e-11 7.1322061e-06 2.0983971e-04 9.9962354e-01\n",
      "  1.3049576e-06 2.9688332e-10 3.6880312e-08 4.3960572e-08 1.5795756e-04\n",
      "  1.3113616e-11 4.4726987e-09]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Answer: 0.0  Prediction: 0 Value: 0.99999905\n",
      "Predict Values [[9.99999046e-01 7.30802014e-08 8.57760531e-13 5.36775679e-10\n",
      "  2.89012009e-10 4.18131224e-11 4.65174719e-13 1.26364735e-11\n",
      "  5.78690595e-10 7.02366265e-07 1.06085750e-07 3.62911839e-10]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Answer: 8.0  Prediction: 8 Value: 1.0\n",
      "Predict Values [[8.1183367e-12 4.6838145e-12 2.7796693e-10 7.0041157e-13 2.8040922e-12\n",
      "  2.4713907e-12 3.6908099e-10 7.4782111e-11 1.0000000e+00 3.5803954e-10\n",
      "  1.7268369e-15 5.8264556e-12]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: 3.0  Prediction: 3 Value: 0.99997437\n",
      "Predict Values [[2.9370839e-10 3.0107915e-14 1.8565570e-08 9.9997437e-01 2.1473570e-05\n",
      "  4.1335315e-06 1.2594839e-12 2.1713509e-08 3.9765885e-10 1.3295283e-10\n",
      "  8.4337755e-09 4.5385971e-08]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Answer: 1.0  Prediction: 1 Value: 0.9999976\n",
      "Predict Values [[2.30391174e-06 9.99997616e-01 1.09820055e-08 8.50606071e-15\n",
      "  5.83336938e-12 5.01443465e-09 3.20743876e-09 7.66023334e-08\n",
      "  2.80769163e-09 2.40798688e-08 1.22072144e-10 2.68862932e-09]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Answer: 2.0  Prediction: 2 Value: 1.0\n",
      "Predict Values [[5.1235408e-16 5.9510605e-11 1.0000000e+00 2.2801816e-11 4.6721127e-10\n",
      "  1.1122803e-09 2.5883169e-15 6.7767564e-10 3.9919484e-11 6.4373923e-11\n",
      "  2.3537580e-17 1.0973048e-12]]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Answer: 2.0  Prediction: 2 Value: 1.0\n",
      "Predict Values [[9.3593265e-16 9.8481071e-11 1.0000000e+00 1.0004313e-11 4.2436318e-11\n",
      "  8.3665014e-10 3.5535671e-15 1.5370956e-09 1.2450885e-10 3.3735046e-11\n",
      "  2.5093585e-18 7.6903416e-14]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: 5.0  Prediction: 5 Value: 0.9999993\n",
      "Predict Values [[1.5683851e-10 1.0475952e-10 2.3611119e-10 8.9247082e-10 6.8229138e-09\n",
      "  9.9999928e-01 7.6590516e-07 1.7033283e-08 1.8243856e-11 1.1663909e-12\n",
      "  7.4206283e-12 1.0168607e-13]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Answer: 7.0  Prediction: 7 Value: 1.0\n",
      "Predict Values [[1.0670976e-13 7.4733264e-13 2.7697815e-11 9.0861518e-10 1.2763334e-12\n",
      "  3.4056372e-10 3.5797604e-10 1.0000000e+00 1.5060017e-11 3.0772808e-11\n",
      "  2.6820718e-11 2.0469056e-12]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Answer: 4.0  Prediction: 4 Value: 0.9999974\n",
      "Predict Values [[1.70694818e-08 2.91425239e-12 2.12090523e-09 3.27635767e-08\n",
      "  9.99997377e-01 3.99124911e-09 4.24005897e-08 1.07628186e-11\n",
      "  1.08100515e-08 2.59009016e-06 5.40838424e-13 7.96335164e-10]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Answer: 10.0  Prediction: 10 Value: 1.0\n",
      "Predict Values [[2.17061551e-08 1.67965219e-12 2.27695331e-14 9.70161885e-12\n",
      "  1.69129363e-11 2.30704738e-14 6.52019030e-17 1.07393885e-11\n",
      "  7.39976453e-14 4.30720862e-13 1.00000000e+00 5.99757466e-11]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: 0.0  Prediction: 0 Value: 0.99999595\n",
      "Predict Values [[9.9999595e-01 3.2449603e-07 5.0152603e-12 1.0800000e-08 1.0353243e-09\n",
      "  1.2236037e-09 5.3208857e-12 3.6664130e-10 4.6863762e-09 2.6914753e-07\n",
      "  3.4688480e-06 3.3054066e-09]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 0.9999987\n",
      "Predict Values [[4.2821786e-09 3.2516773e-08 2.9197812e-08 3.2097695e-08 4.2418299e-07\n",
      "  4.5015125e-07 9.7655452e-08 8.2795530e-08 7.9088018e-08 5.7305813e-09\n",
      "  9.4383743e-08 9.9999869e-01]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Answer: 6.0  Prediction: 6 Value: 0.9999995\n",
      "Predict Values [[1.7427483e-11 9.2739363e-09 8.5092150e-10 1.8825234e-16 1.8886694e-09\n",
      "  3.5654037e-07 9.9999952e-01 7.4771634e-08 4.2333277e-12 6.1554043e-12\n",
      "  2.2531542e-16 6.8330525e-15]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Answer: 8.0  Prediction: 8 Value: 1.0\n",
      "Predict Values [[3.3884067e-15 1.8886364e-18 2.0093869e-16 2.3493380e-15 2.1663405e-14\n",
      "  5.8668397e-18 1.3267972e-12 1.9612211e-14 1.0000000e+00 4.1052550e-11\n",
      "  3.6536270e-20 6.7370897e-13]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: 0.0  Prediction: 0 Value: 0.9999939\n",
      "Predict Values [[9.9999392e-01 1.5871535e-06 1.5873082e-11 1.1156587e-08 1.4620363e-09\n",
      "  1.0124396e-08 2.5518715e-10 4.2653094e-09 1.7589981e-08 1.5628137e-06\n",
      "  2.8847967e-06 2.3819575e-09]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Answer: 1.0  Prediction: 1 Value: 0.9999285\n",
      "Predict Values [[7.0428134e-05 9.9992847e-01 3.0459717e-08 2.3425248e-12 2.5966482e-10\n",
      "  1.7505886e-07 2.9849438e-08 5.3409468e-07 1.5336656e-08 1.6708064e-08\n",
      "  1.6853630e-08 2.4674100e-07]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Answer: 9.0  Prediction: 9 Value: 1.0\n",
      "Predict Values [[8.2733421e-12 1.0973931e-15 1.4867862e-17 1.8262469e-14 6.8339527e-12\n",
      "  3.7232931e-17 4.9242620e-13 4.5366654e-14 2.0990678e-11 1.0000000e+00\n",
      "  3.4898316e-18 2.6068479e-14]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Answer: 8.0  Prediction: 8 Value: 1.0\n",
      "Predict Values [[6.8074095e-13 1.9153006e-17 1.3897295e-15 4.7637637e-13 1.1339523e-12\n",
      "  1.4560852e-15 1.0597769e-10 8.8731870e-13 1.0000000e+00 3.6424659e-09\n",
      "  1.5057875e-17 1.8428266e-13]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Answer: 2.0  Prediction: 2 Value: 0.9999999\n",
      "Predict Values [[1.17952955e-14 4.80114282e-10 9.99999881e-01 9.64673341e-10\n",
      "  1.67104055e-08 9.65153624e-10 8.62414727e-14 9.15960374e-09\n",
      "  4.01276734e-10 6.35540243e-09 7.13087562e-14 8.29051388e-08]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: 5.0  Prediction: 5 Value: 0.99997187\n",
      "Predict Values [[3.33843675e-10 2.47076870e-09 6.13266522e-08 6.62973632e-09\n",
      "  1.02605696e-07 9.99971867e-01 2.74348131e-05 4.25291205e-07\n",
      "  2.35229680e-09 3.38470779e-11 7.79468771e-15 2.26211324e-12]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: 2.0  Prediction: 2 Value: 0.99999964\n",
      "Predict Values [[1.3531512e-12 4.5301924e-08 9.9999964e-01 3.2051823e-09 1.8897229e-08\n",
      "  3.4720948e-08 7.6128366e-12 2.3508102e-07 1.4429849e-08 3.6177070e-08\n",
      "  2.2293219e-13 2.0567310e-09]]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Answer: 9.0  Prediction: 9 Value: 0.99998987\n",
      "Predict Values [[8.9013947e-06 4.0590989e-10 4.9445701e-09 5.7079779e-07 6.0204036e-07\n",
      "  6.2191514e-09 9.3014230e-10 3.8102352e-09 5.9370814e-10 9.9998987e-01\n",
      "  3.6743334e-08 1.3680449e-11]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Answer: 6.0  Prediction: 6 Value: 1.0\n",
      "Predict Values [[2.7191297e-13 6.8216331e-12 2.9978908e-13 5.1239680e-17 2.1017760e-11\n",
      "  5.6783173e-10 1.0000000e+00 5.3689626e-09 2.2017656e-10 3.7175189e-12\n",
      "  5.0081146e-18 1.2357472e-11]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: 4.0  Prediction: 4 Value: 0.99999774\n",
      "Predict Values [[1.0153752e-08 1.1292005e-10 6.1353916e-10 2.0517051e-08 9.9999774e-01\n",
      "  2.0782372e-06 4.9198490e-09 9.2841575e-11 4.4703016e-10 2.0445044e-07\n",
      "  6.8160733e-13 5.7770944e-10]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Answer: 11.0  Prediction: 11 Value: 0.999998\n",
      "Predict Values [[3.3355359e-08 6.4505905e-08 1.9618160e-10 7.7705814e-10 1.5968088e-09\n",
      "  6.4093519e-10 1.2864365e-09 4.0530860e-08 4.8362747e-08 4.3285656e-08\n",
      "  1.8767688e-06 9.9999797e-01]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Answer: 3.0  Prediction: 3 Value: 0.9999994\n",
      "Predict Values [[4.6509355e-12 4.9589342e-17 9.8885944e-10 9.9999940e-01 5.6066045e-07\n",
      "  5.7307386e-09 1.0332153e-16 9.4884245e-10 1.2189192e-12 1.1917493e-11\n",
      "  6.4100116e-09 3.8853106e-13]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Answer: 10.0  Prediction: 10 Value: 1.0\n",
      "Predict Values [[1.0678322e-10 2.7511215e-15 9.3339859e-14 5.4971902e-11 8.6759708e-14\n",
      "  3.6267752e-14 2.8776853e-18 2.5239937e-11 1.2441866e-13 1.1849093e-15\n",
      "  1.0000000e+00 2.4099509e-11]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Answer: 4.0  Prediction: 4 Value: 0.99999726\n",
      "Predict Values [[3.8032255e-10 1.3727454e-13 7.4908320e-09 6.1115134e-07 9.9999726e-01\n",
      "  1.3622663e-06 9.2017274e-09 1.2607856e-10 3.3992031e-10 6.7773686e-07\n",
      "  4.0508813e-15 1.5004557e-07]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Answer: 6.0  Prediction: 6 Value: 0.99999595\n",
      "Predict Values [[9.5754854e-12 2.6539798e-08 1.5735502e-08 1.7014813e-12 2.0790326e-08\n",
      "  3.1135980e-06 9.9999595e-01 9.3861473e-07 1.0946874e-08 8.0282128e-11\n",
      "  7.7716025e-14 5.5906630e-11]]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Answer: 8.0  Prediction: 8 Value: 1.0\n",
      "Predict Values [[6.3452276e-13 3.3104824e-15 3.9218683e-14 7.2472936e-13 4.8279311e-13\n",
      "  4.9639764e-15 5.8716740e-11 2.4049275e-11 1.0000000e+00 5.4482920e-09\n",
      "  2.5404409e-17 2.2066190e-12]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Answer: 2.0  Prediction: 2 Value: 0.9999988\n",
      "Predict Values [[6.4784731e-12 8.7364988e-08 9.9999881e-01 5.7439764e-09 1.0745165e-09\n",
      "  3.8743661e-08 1.1071443e-12 1.0054196e-06 1.8500230e-09 6.0890599e-09\n",
      "  4.2910635e-14 2.2104310e-10]]\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Answer: 8.0  Prediction: 8 Value: 1.0\n",
      "Predict Values [[1.2036109e-14 1.2915402e-17 1.3605493e-14 1.8362548e-13 5.1388585e-12\n",
      "  5.7298036e-16 6.6243927e-11 1.5766297e-12 1.0000000e+00 4.5627369e-09\n",
      "  5.4192143e-19 3.4535312e-11]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Answer: 3.0  Prediction: 3 Value: 1.0\n",
      "Predict Values [[2.2948293e-14 2.3064496e-21 1.4943296e-12 1.0000000e+00 3.4227284e-08\n",
      "  4.7080963e-12 4.1151160e-19 5.0327711e-11 1.2223627e-13 1.9738126e-13\n",
      "  3.2080688e-10 1.8694009e-15]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: 9.0  Prediction: 9 Value: 0.9999974\n",
      "Predict Values [[4.74452378e-07 5.12224663e-09 2.12528324e-12 2.10278895e-11\n",
      "  1.35908895e-09 8.12358167e-12 1.26029831e-09 1.16587007e-09\n",
      "  1.10678876e-07 9.99997377e-01 1.74406808e-11 2.05602737e-06]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: 3.0  Prediction: 3 Value: 1.0\n",
      "Predict Values [[2.8120108e-14 3.6227457e-21 5.1589879e-13 1.0000000e+00 3.4929329e-08\n",
      "  1.3086385e-12 6.5790730e-19 5.4303593e-11 2.5822458e-12 8.4731706e-13\n",
      "  2.2161593e-09 7.1047895e-16]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Answer: 6.0  Prediction: 6 Value: 0.9999988\n",
      "Predict Values [[1.51422607e-11 8.20784607e-10 1.12385309e-11 3.15112553e-14\n",
      "  1.98546554e-10 1.04139906e-06 9.99998808e-01 1.01481525e-07\n",
      "  6.52754795e-10 4.07156036e-12 3.92850196e-15 4.77887285e-10]]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Answer: 1.0  Prediction: 1 Value: 1.0\n",
      "Predict Values [[4.3577404e-09 1.0000000e+00 7.8006277e-09 2.0495726e-17 1.4768856e-13\n",
      "  5.6108573e-10 1.4148395e-10 1.1964247e-09 3.2052460e-12 3.7300572e-11\n",
      "  1.0769330e-12 6.1693269e-11]]\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Answer: 4.0  Prediction: 4 Value: 0.9999354\n",
      "Predict Values [[1.4097359e-09 5.8887235e-11 1.9279652e-05 9.6778458e-06 9.9993539e-01\n",
      "  4.2977795e-06 2.5695121e-08 1.5589212e-07 1.7408853e-08 3.1129894e-05\n",
      "  4.9204676e-14 7.7204840e-11]]\n",
      "\n",
      "Test Score:  49 / 50  =  0.98\n"
     ]
    }
   ],
   "source": [
    "# TEST: Load model and run it against test set\n",
    "model = models.load_model(model_filename)\n",
    "correct = 0\n",
    "testRange = 50\n",
    "for i in range(1, testRange):\n",
    "    maxV = -1\n",
    "    predict = -1\n",
    "    counter = 0\n",
    "    pre = model.predict(np.expand_dims(x_test[i], 0))\n",
    "    for j in range(12):\n",
    "        #print(pre[0][j])\n",
    "        if(pre[0][j] > maxV):\n",
    "            maxV = pre[0][j]\n",
    "            predict = counter\n",
    "        counter = counter + 1\n",
    "            \n",
    "    print('Answer:', y_test[i], ' Prediction:', predict, 'Value:', maxV)\n",
    "    print(\"Predict Values\", pre)\n",
    "    if y_test[i] == predict:\n",
    "        correct = correct+1\n",
    "print()\n",
    "print(\"Test Score: \", correct, \"/\",testRange,\" = \", correct/testRange) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0451 - acc: 0.9844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04511293023824692, 0.984375]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model with test set\n",
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
